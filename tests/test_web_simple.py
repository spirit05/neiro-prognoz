# [file name]: tests/test_web_simple.py
"""
–£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –≤–µ–±-—Å–µ—Ä–≤–∏—Å–∞ (–±–µ–∑ pytest)
"""

import sys
import os
import tempfile
import json

sys.path.insert(0, '/opt/dev')

def test_basic_imports():
    """–¢–µ—Å—Ç –±–∞–∑–æ–≤—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤"""
    print("üîç –¢–ï–°–¢ –ë–ê–ó–û–í–´–• –ò–ú–ü–û–†–¢–û–í...")
    
    try:
        from web.components.ml_adapter import MLSystemAdapter
        from web.components.sidebar import show_sidebar
        from web.components.training_ui import show_training_ui
        from web.components.prediction_ui import show_prediction_ui
        from web.components.data_ui import show_data_ui
        from web.components.status_ui import show_status_ui
        
        print("‚úÖ –í—Å–µ –≤–µ–±-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–º–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        from ml.core.trainer import EnhancedTrainer
        from ml.core.predictor import EnhancedPredictor
        from ml.learning.self_learning import SelfLearningSystem
        from ml.utils.data_utils import load_dataset, save_dataset
        
        print("‚úÖ –í—Å–µ ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–º–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è")
        
        return True
        
    except ImportError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        return False

def test_ml_adapter_simple():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç ML –∞–¥–∞–ø—Ç–µ—Ä–∞"""
    print("\nüîç –ü–†–û–°–¢–û–ô –¢–ï–°–¢ ML –ê–î–ê–ü–¢–ï–†–ê...")
    
    try:
        from web.components.ml_adapter import MLSystemAdapter
        
        # –°–æ–∑–¥–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä
        adapter = MLSystemAdapter()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
        assert hasattr(adapter, 'is_trained')
        assert hasattr(adapter, 'trainer')
        assert hasattr(adapter, 'predictor')
        
        print("‚úÖ ML –∞–¥–∞–ø—Ç–µ—Ä —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–æ–¥—ã
        status = adapter.get_status()
        assert isinstance(status, dict)
        assert 'is_trained' in status
        assert 'dataset_size' in status
        
        print("‚úÖ –ú–µ—Ç–æ–¥ get_status() —Ä–∞–±–æ—Ç–∞–µ—Ç")
        
        insights = adapter.get_learning_insights()
        assert isinstance(insights, dict)
        
        print("‚úÖ –ú–µ—Ç–æ–¥ get_learning_insights() —Ä–∞–±–æ—Ç–∞–µ—Ç")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞–¥–∞–ø—Ç–µ—Ä–∞: {e}")
        return False

def test_data_operations():
    """–¢–µ—Å—Ç –æ–ø–µ—Ä–∞—Ü–∏–π —Å –¥–∞–Ω–Ω—ã–º–∏"""
    print("\nüîç –¢–ï–°–¢ –û–ü–ï–†–ê–¶–ò–ô –° –î–ê–ù–ù–´–ú–ò...")
    
    try:
        from ml.utils.data_utils import load_dataset, save_dataset, validate_group
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            test_data = ["1 2 3 4", "5 6 7 8", "9 10 11 12"]
            test_file = os.path.join(temp_dir, 'test_data.json')
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            save_dataset(test_data)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            loaded_data = load_dataset()
            assert loaded_data == test_data
            print("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç–∞—é—Ç")
            
            # –¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            assert validate_group("1 2 3 4") == True
            assert validate_group("1 1 3 4") == False  # –î—É–±–ª–∏–∫–∞—Ç—ã
            assert validate_group("1 2 3") == False    # –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å–µ–ª
            print("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –≥—Ä—É–ø–ø —Ä–∞–±–æ—Ç–∞–µ—Ç")
            
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–ø–µ—Ä–∞—Ü–∏–π —Å –¥–∞–Ω–Ω—ã–º–∏: {e}")
        return False

def test_web_workflow():
    """–¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–≥–æ workflow –≤–µ–±-—Å–µ—Ä–≤–∏—Å–∞"""
    print("\nüîç –¢–ï–°–¢ –ë–ê–ó–û–í–û–ì–û WORKFLOW...")
    
    try:
        from web.components.ml_adapter import MLSystemAdapter
        from ml.utils.data_utils import load_dataset, save_dataset
        
        with tempfile.TemporaryDirectory() as temp_dir:
            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            test_data = ["1 2 3 4", "5 6 7 8"] * 30  # 60 –≥—Ä—É–ø–ø
            dataset_path = os.path.join(temp_dir, 'dataset.json')
            
            with open(dataset_path, 'w') as f:
                json.dump(test_data, f)
            
            # –°–æ–∑–¥–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä
            adapter = MLSystemAdapter()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
            status = adapter.get_status()
            print(f"üìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã: {status}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–∏—Å—Ç–µ–º–∞ –≤–∏–¥–∏—Ç –¥–∞–Ω–Ω—ã–µ
            assert status['dataset_size'] == 60
            assert status['has_sufficient_data'] == True
            
            print("‚úÖ –ë–∞–∑–æ–≤—ã–π workflow —Ä–∞–±–æ—Ç–∞–µ—Ç")
            
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ workflow: {e}")
        return False

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üéØ –£–ü–†–û–©–ï–ù–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –í–ï–ë-–°–ï–†–í–ò–°–ê")
    print("=" * 50)
    
    tests = [
        test_basic_imports,
        test_ml_adapter_simple, 
        test_data_operations,
        test_web_workflow
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        if test():
            passed += 1
    
    print("\n" + "=" * 50)
    print(f"üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´: {passed}/{total} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    
    if passed == total:
        print("üéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´! –í–µ–±-—Å–µ—Ä–≤–∏—Å –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.")
        return 0
    else:
        print("‚ö†Ô∏è  –ù–ï–ö–û–¢–û–†–´–ï –¢–ï–°–¢–´ –ù–ï –ü–†–û–ô–î–ï–ù–´. –¢—Ä–µ–±—É–µ—Ç—Å—è –æ—Ç–ª–∞–¥–∫–∞.")
        return 1

if __name__ == "__main__":
    exit(main())
