# /opt/model/tests/test_ensemble_real_data.py
"""
–¢–ï–°–¢ –†–ï–ê–õ–¨–ù–û–ô –†–ê–ë–û–¢–û–°–ü–û–°–û–ë–ù–û–°–¢–ò –ê–ù–°–ê–ú–ë–õ–ï–í–û–ô –°–ò–°–¢–ï–ú–´
"""

import sys
import os
import numpy as np
import pandas as pd

sys.path.insert(0, '/opt/model')

from ml.core.types import DataBatch, TrainingConfig, DataType
from ml.ensemble import WeightedEnsemblePredictor, StatisticalPredictor, PatternBasedPredictor, FrequencyPredictor


def test_ensemble_with_realistic_data():
    """–¢–µ—Å—Ç –∞–Ω—Å–∞–º–±–ª—è —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    print("üéØ –¢–ï–°–¢ –†–ï–ê–õ–¨–ù–û–ô –†–ê–ë–û–¢–û–°–ü–û–°–û–ë–ù–û–°–¢–ò")
    
    # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–ø–æ—Ö–æ–∂–∏–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é —á–∏—Å–µ–ª)
    realistic_data = [
        [5, 12, 18, 23],
        [3, 8, 15, 21], 
        [7, 14, 19, 25],
        [2, 9, 16, 22],
        [6, 13, 20, 26],
        [4, 11, 17, 24],
        [1, 10, 15, 23],
        [5, 12, 19, 25],
        [3, 8, 16, 22],
        [7, 14, 20, 26]
    ]
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å
    ensemble = WeightedEnsemblePredictor("real_data_test")
    
    statistical = StatisticalPredictor("statistical")
    pattern = PatternBasedPredictor("pattern") 
    frequency = FrequencyPredictor("frequency")
    
    ensemble.add_predictor("statistical", statistical, 0.35)
    ensemble.add_predictor("pattern", pattern, 0.25)
    ensemble.add_predictor("frequency", frequency, 0.20)
    
    # –û–±—É—á–∞–µ–º –Ω–∞ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    data_batch = DataBatch(
        data=pd.DataFrame(realistic_data),
        batch_id="real_data_train",
        data_type=DataType.TRAINING
    )
    
    config = TrainingConfig(epochs=3)
    result = ensemble.train(data_batch, config)
    
    print(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {result.status.value}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    test_data = [
        [4, 11, 18, 24],
        [2, 9, 17, 23],
        [6, 13, 19, 25]
    ]
    
    pred_batch = DataBatch(
        data=pd.DataFrame(test_data),
        batch_id="real_data_pred",
        data_type=DataType.PREDICTION  
    )
    
    response = ensemble.predict(pred_batch)
    
    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(response.predictions)} –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
    for i, prediction in enumerate(response.predictions[:3]):
        print(f"–ü—Ä–æ–≥–Ω–æ–∑ {i+1}: {prediction}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∞
        assert len(prediction) == 4, "–ü—Ä–æ–≥–Ω–æ–∑ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 4 —á–∏—Å–ª–∞"
        assert all(1 <= x <= 26 for x in prediction), "–í—Å–µ —á–∏—Å–ª–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 1-26"
        assert prediction[0] != prediction[1], "–ü–µ—Ä–≤–∞—è –ø–∞—Ä–∞ –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å —Ä–∞–∑–Ω—ã–µ —á–∏—Å–ª–∞"
        assert prediction[2] != prediction[3], "–í—Ç–æ—Ä–∞—è –ø–∞—Ä–∞ –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å —Ä–∞–∑–Ω—ã–µ —á–∏—Å–ª–∞"
        
        print(f"  ‚úÖ –ü—Ä–æ–≥–Ω–æ–∑ {i+1} –≤–∞–ª–∏–¥–µ–Ω")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–∞–∑–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–∞—é—Ç —Ä–∞–∑–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    statistical_response = statistical.predict(pred_batch)
    pattern_response = pattern.predict(pred_batch)
    frequency_response = frequency.predict(pred_batch)
    
    print(f"üìä StatisticalPredictor: {len(statistical_response.predictions)} –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
    print(f"üìä PatternBasedPredictor: {len(pattern_response.predictions)} –ø—Ä–æ–≥–Ω–æ–∑–æ–≤") 
    print(f"üìä FrequencyPredictor: {len(frequency_response.predictions)} –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—è–º–∏ (—Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏)
    statistical_groups = set([tuple(pred) for pred in statistical_response.predictions])
    pattern_groups = set([tuple(pred) for pred in pattern_response.predictions])
    frequency_groups = set([tuple(pred) for pred in frequency_response.predictions])
    
    # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–∑–ª–∏—á–∏—è (–Ω–æ –º–æ–≥—É—Ç –±—ã—Ç—å –∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è)
    all_unique = len(statistical_groups.union(pattern_groups).union(frequency_groups))
    print(f"üîÄ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –æ—Ç –≤—Å–µ—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π: {all_unique}")
    
    assert all_unique > 0, "–î–æ–ª–∂–Ω—ã –±—ã—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã –æ—Ç —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π"
    
    print("üéâ –¢–ï–°–¢ –†–ï–ê–õ–¨–ù–û–ô –†–ê–ë–û–¢–û–°–ü–û–°–û–ë–ù–û–°–¢–ò –ü–†–û–ô–î–ï–ù!")
    return True


def test_individual_predictors_detailed():
    """–î–µ—Ç–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª–µ–π"""
    print("\nüîç –î–ï–¢–ê–õ–¨–ù–´–ô –¢–ï–°–¢ –ò–ù–î–ò–í–ò–î–£–ê–õ–¨–ù–´–• –ü–†–ï–î–°–ö–ê–ó–ê–¢–ï–õ–ï–ô")
    
    test_data = [
        [1, 8, 15, 22],
        [3, 10, 17, 24], 
        [5, 12, 19, 26],
        [2, 9, 16, 23],
        [4, 11, 18, 25]
    ]
    
    data_batch = DataBatch(
        data=pd.DataFrame(test_data),
        batch_id="detailed_test",
        data_type=DataType.TRAINING
    )
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º StatisticalPredictor
    print("\nüìä StatisticalPredictor:")
    statistical = StatisticalPredictor("statistical_detailed")
    statistical.train(data_batch, TrainingConfig(epochs=2))
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    history = [1, 5, 12, 18, 3, 9, 15, 21, 6, 11, 19, 24, 8, 13, 20, 25]
    test_batch = DataBatch(
        data=pd.DataFrame([history]),
        batch_id="pattern_test", 
        data_type=DataType.PREDICTION
    )
    
    response = statistical.predict(test_batch)
    print(f"  –ü—Ä–æ–≥–Ω–æ–∑—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {len(response.predictions)}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º PatternBasedPredictor
    print("\nüîç PatternBasedPredictor:")
    pattern = PatternBasedPredictor("pattern_detailed")
    pattern.train(data_batch, TrainingConfig(epochs=2))
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∏—Å–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
    sequences = pattern._find_sequences(history)
    print(f"  –ù–∞–π–¥–µ–Ω–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {len(sequences)}")
    for seq in sequences:
        print(f"    –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {seq}")
    
    response = pattern.predict(test_batch)
    print(f"  –ü—Ä–æ–≥–Ω–æ–∑—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {len(response.predictions)}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º FrequencyPredictor
    print("\nüìà FrequencyPredictor:")
    frequency = FrequencyPredictor("frequency_detailed")
    frequency.train(data_batch, TrainingConfig(epochs=2))
    
    print(f"  –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –≥—Ä—É–ø–ø: {frequency.total_groups}")
    print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —á–∏—Å–µ–ª: {len(frequency.number_frequencies)}")
    print(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ä: {len(frequency.pair_frequencies)}")
    
    response = frequency.predict(test_batch)
    print(f"  –ü—Ä–æ–≥–Ω–æ–∑—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–æ—Ç: {len(response.predictions)}")
    
    print("‚úÖ –î–ï–¢–ê–õ–¨–ù–´–ô –¢–ï–°–¢ –ü–†–û–ô–î–ï–ù!")
    return True


if __name__ == "__main__":
    try:
        test_ensemble_with_realistic_data()
        test_individual_predictors_detailed()
        print("\nüéâ –í–°–ï –¢–ï–°–¢–´ –†–ï–ê–õ–¨–ù–û–ô –†–ê–ë–û–¢–û–°–ü–û–°–û–ë–ù–û–°–¢–ò –ü–†–û–ô–î–ï–ù–´!")
    except Exception as e:
        print(f"‚ùå –¢–ï–°–¢ –ü–†–û–í–ê–õ–ï–ù: {e}")
        import traceback
        traceback.print_exc()
        exit(1)
