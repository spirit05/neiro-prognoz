# [file name]: tests/test_dataprocessor_integration.py
"""
–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ feature engineers —Å DataProcessor
"""

import pytest
import numpy as np
import sys
import os

sys.path.insert(0, '/opt/model')

def test_dataprocessor_with_feature_engineers():
    """–¢–µ—Å—Ç —á—Ç–æ DataProcessor –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å feature engineers"""
    try:
        from ml.core.data_processor import DataProcessor
        
        # –°–æ–∑–¥–∞–µ–º DataProcessor
        processor = DataProcessor(history_size=20)
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_groups = [
            "1 2 3 4", "5 6 7 8", "9 10 11 12", "13 14 15 16", "17 18 19 20",
            "21 22 23 24", "1 3 5 7", "2 4 6 8", "9 11 13 15", "10 12 14 16"
        ]
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏—á –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        prediction_features = processor.create_prediction_features(test_groups)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∏—á–∏ —Å–æ–∑–¥–∞–Ω—ã
        assert prediction_features is not None, "Prediction features are None"
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ñ–∏—á–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        if len(prediction_features) > 0:
            if isinstance(prediction_features, np.ndarray):
                feature_vector = prediction_features
            else:
                feature_vector = prediction_features[0] if len(prediction_features) > 0 else None
            
            if feature_vector is not None:
                assert isinstance(feature_vector, np.ndarray), f"Features are not numpy array: {type(feature_vector)}"
                assert feature_vector.dtype == np.float32, f"Wrong dtype: {feature_vector.dtype}"
                print(f"‚úÖ Prediction features created: {feature_vector.shape}")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        training_groups = test_groups * 3  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
        
        features, targets = processor.prepare_training_data(training_groups)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç–æ –µ—Å–ª–∏ –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö)
        if len(features) > 0:
            assert features.shape[0] == targets.shape[0], "Features and targets count mismatch"
            assert features.dtype == np.float32, f"Wrong features dtype: {features.dtype}"
            assert targets.dtype == np.int64, f"Wrong targets dtype: {targets.dtype}"
            print(f"‚úÖ Training data prepared: {features.shape[0]} samples with {features.shape[1]} features")
        else:
            print("‚ö†Ô∏è No training data generated (may be normal for small datasets)")
        
        print("‚úÖ DataProcessor integration test passed")
        return True
        
    except Exception as e:
        pytest.fail(f"DataProcessor integration test failed: {e}")

def test_feature_consistency():
    """–¢–µ—Å—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ñ–∏—á –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –≤—ã–∑–æ–≤–∞—Ö"""
    try:
        from ml.features.engineers.statistical import StatisticalEngineer
        
        engineer = StatisticalEngineer(history_size=10)
        test_data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
        
        # –ü–µ—Ä–≤—ã–π –≤—ã–∑–æ–≤
        features1 = engineer.extract_features(test_data)
        
        # –í—Ç–æ—Ä–æ–π –≤—ã–∑–æ–≤ —Å —Ç–µ–º–∏ –∂–µ –¥–∞–Ω–Ω—ã–º–∏
        features2 = engineer.extract_features(test_data)
        
        # –§–∏—á–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–º–∏
        assert np.array_equal(features1, features2), "Features are not consistent between calls"
        
        print("‚úÖ Feature consistency test passed")
        return True
        
    except Exception as e:
        pytest.fail(f"Feature consistency test failed: {e}")

if __name__ == "__main__":
    test_dataprocessor_with_feature_engineers()
    test_feature_consistency()
    print("üéâ –í—Å–µ —Ç–µ—Å—Ç—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å DataProcessor –ø—Ä–æ–π–¥–µ–Ω—ã!")
