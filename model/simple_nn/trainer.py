from config.paths import paths
# [file name]: model/simple_nn/trainer.py (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô)
"""
–û–±—É—á–µ–Ω–∏–µ –£–°–ò–õ–ï–ù–ù–û–ô –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from typing import List, Tuple
import os
import time
import gc
from .model import EnhancedNumberPredictor
from .data_processor import DataProcessor

class EnhancedTrainer:
    def __init__(self, model_path: str = "data/simple_model.pth"):
        self.model_path = model_path
        self.device = torch.device('cpu')
        self.model = None
        self.criterion = nn.CrossEntropyLoss()
        self.progress_callback = None
    
    def set_progress_callback(self, callback):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        self.progress_callback = callback
    
    def _report_progress(self, message):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ —Å –∑–∞–ø–∏—Å—å—é –≤ —Ñ–∞–π–ª"""
        import datetime
        timestamp = datetime.datetime.now().strftime('%H:%M:%S')
        formatted_message = f"{timestamp} - {message}"
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª
        try:
            with open(paths.TRAINING_LOG, "a", encoding="utf-8") as f:
                f.write(formatted_message + "\n")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ –ª–æ–≥: {e}")
        
        # –°—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞
        if self.progress_callback:
            self.progress_callback(message)
        else:
            print(f"üì¢ {message}")
    
    def train(self, groups: List[str], epochs: int = 20, batch_size: int = 64) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        total_start_time = time.time()
        
        self._report_progress(f"üöÄ –°–¢–ê–†–¢ –æ–±—É—á–µ–Ω–∏—è: {len(groups)} –≥—Ä—É–ø–ø, {epochs} —ç–ø–æ—Ö, batch_size={batch_size}")
        
        # –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        stage1_start = time.time()
        self._report_progress("üìä –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        processor = DataProcessor(history_size=25)
        features, targets = processor.prepare_training_data(groups)
        
        stage1_time = time.time() - stage1_start
        self._report_progress(f"‚úÖ –≠—Ç–∞–ø 1 –∑–∞–≤–µ—Ä—à–µ–Ω: {stage1_time:.1f} —Å–µ–∫")
        
        if len(features) == 0:
            self._report_progress("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return []
        
        if len(features) < 100:
            self._report_progress(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(features)} –ø—Ä–∏–º–µ—Ä–æ–≤ (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 100)")
            return []
        
        self._report_progress(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(groups)} –≥—Ä—É–ø–ø, {len(groups)*4} —á–∏—Å–µ–ª")
        self._report_progress(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(features)} –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
        
        # –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        stage2_start = time.time()
        self._report_progress("üîß –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        
        # –í—Å–µ–≥–¥–∞ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        self.model = EnhancedNumberPredictor(input_size=features.shape[1], hidden_size=256)
        self.model.to(self.device)
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –¥–ª—è 4 –ì–ë RAM
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
        
        stage2_time = time.time() - stage2_start
        self._report_progress(f"‚úÖ –≠—Ç–∞–ø 2 –∑–∞–≤–µ—Ä—à–µ–Ω: {stage2_time:.1f} —Å–µ–∫")
        
        # –≠—Ç–∞–ø 3: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
        stage3_start = time.time()
        self._report_progress("‚öôÔ∏è –≠—Ç–∞–ø 3: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞...")
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π optimizer —Å learning rate scheduling
        self.optimizer = optim.AdamW(self.model.parameters(), lr=0.001, weight_decay=1e-4)
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.5, patience=3)
        
        stage3_time = time.time() - stage3_start
        self._report_progress(f"‚úÖ –≠—Ç–∞–ø 3 –∑–∞–≤–µ—Ä—à–µ–Ω: {stage3_time:.1f} —Å–µ–∫")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU —Ç–µ–Ω–∑–æ—Ä—ã
        features_tensor = torch.tensor(features, dtype=torch.float32)
        targets_tensor = torch.tensor(targets, dtype=torch.long) - 1
        
        # –≠—Ç–∞–ø 4: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        stage4_start = time.time()
        self._report_progress("üß† –≠—Ç–∞–ø 4: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
        
        self.model.train()
        best_loss = float('inf')
        patience_counter = 0
        patience = 5
        
        for epoch in range(epochs):
            epoch_start_time = time.time()
            
            # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∞–∂–¥—ã–π —ç–ø–æ—Ö
            indices = torch.randperm(len(features))
            features_shuffled = features_tensor[indices]
            targets_shuffled = targets_tensor[indices]
            
            total_loss = 0
            num_batches = 0
            
            for i in range(0, len(features), batch_size):
                batch_start = i
                batch_end = min(i + batch_size, len(features))
                
                if batch_end - batch_start < 2:
                    continue
                    
                batch_features = features_shuffled[batch_start:batch_end]
                batch_targets = targets_shuffled[batch_start:batch_end]
                
                self.optimizer.zero_grad()
                outputs = self.model(batch_features)
                
                loss = 0
                for j in range(4):
                    loss += self.criterion(outputs[:, j, :], batch_targets[:, j])
                loss = loss / 4
                
                # L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
                l2_lambda = 0.001
                l2_norm = sum(p.pow(2.0).sum() for p in self.model.parameters())
                loss = loss + l2_lambda * l2_norm
                
                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                self.optimizer.step()
                
                total_loss += loss.item()
                num_batches += 1
            
            epoch_time = time.time() - epoch_start_time
            
            if num_batches > 0:
                avg_loss = total_loss / num_batches
                current_lr = self.optimizer.param_groups[0]['lr']
                
                self._report_progress(f"üìà –≠–ø–æ—Ö–∞ {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, LR: {current_lr:.6f}, –í—Ä–µ–º—è: {epoch_time:.1f} —Å–µ–∫")
                
                self.scheduler.step(avg_loss)
                
                if avg_loss < best_loss:
                    best_loss = avg_loss
                    self._save_model()
                    patience_counter = 0
                    self._report_progress(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å (loss: {avg_loss:.4f})")
                else:
                    patience_counter += 1
                    if patience_counter >= patience:
                        self._report_progress(f"üõë –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ —ç–ø–æ—Ö–µ {epoch+1}")
                        break
            else:
                self._report_progress(f"‚ö†Ô∏è  –≠–ø–æ—Ö–∞ {epoch+1}/{epochs}: –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –±–∞—Ç—á–µ–π")
        
        stage4_time = time.time() - stage4_start
        self._report_progress(f"‚úÖ –≠—Ç–∞–ø 4 –∑–∞–≤–µ—Ä—à–µ–Ω: {stage4_time:.1f} —Å–µ–∫")
        self._report_progress(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –õ—É—á—à–∏–π loss: {best_loss:.4f}")
        
        # –≠—Ç–∞–ø 5: –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        stage5_start = time.time()
        self._report_progress("üìä –≠—Ç–∞–ø 5: –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
        
        self._analyze_model_performance(features_tensor, targets_tensor)
        
        stage5_time = time.time() - stage5_start
        self._report_progress(f"‚úÖ –≠—Ç–∞–ø 5 –∑–∞–≤–µ—Ä—à–µ–Ω: {stage5_time:.1f} —Å–µ–∫")
        
        # –≠—Ç–∞–ø 6: –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        stage6_start = time.time()
        self._report_progress("üßπ –≠—Ç–∞–ø 6: –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏...")
        
        # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
        del features_tensor, targets_tensor, features_shuffled, targets_shuffled
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        stage6_time = time.time() - stage6_start
        self._report_progress(f"‚úÖ –≠—Ç–∞–ø 6 –∑–∞–≤–µ—Ä—à–µ–Ω: {stage6_time:.1f} —Å–µ–∫")
        
        total_time = time.time() - total_start_time
        self._report_progress(f"üéâ –í–°–ï –≠–¢–ê–ü–´ –ó–ê–í–ï–†–®–ï–ù–´! –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.1f} —Å–µ–∫")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
        self._report_progress("üîÆ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è...")
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π predictor –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
        from .predictor import EnhancedPredictor
        predictor = EnhancedPredictor(self.model_path)
        if predictor.load_model():
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            recent_numbers = []
            for group_str in groups[-25:]:
                try:
                    numbers = [int(x) for x in group_str.strip().split()]
                    if len(numbers) == 4:
                        recent_numbers.extend(numbers)
                except:
                    continue
            
            if len(recent_numbers) >= 50:
                predictions = predictor.predict_group(recent_numbers, 10)
                self._report_progress(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(predictions)} –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
                return predictions
        
        self._report_progress("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—ã")
        return []
    
    def _analyze_model_performance(self, features_tensor: torch.Tensor, targets_tensor: torch.Tensor):
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        self._report_progress("üîç –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏...")
        
        self.model.eval()
        with torch.no_grad():
            test_size = min(1000, len(features_tensor))
            test_features = features_tensor[:test_size]
            test_targets = targets_tensor[:test_size] + 1
            
            self._report_progress(f"üìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ {test_size} –ø—Ä–∏–º–µ—Ä–∞—Ö...")
            
            outputs = self.model(test_features)
            predictions = torch.argmax(outputs, dim=-1) + 1
            
            correct = (predictions == test_targets).float()
            accuracy = correct.mean().item()
            
            self._report_progress(f"üìä Accuracy –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {accuracy:.4f}")
            
            unique_predictions = len(torch.unique(predictions))
            self._report_progress(f"üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö —á–∏—Å–µ–ª: {unique_predictions}/26")
    
    def _save_model(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        self._report_progress("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∏—Å–∫...")
        
        if self.model is not None:
            os.makedirs(os.path.dirname(self.model_path), exist_ok=True)
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'model_config': {
                    'input_size': self.model.feature_extractor[0].in_features,
                    'hidden_size': self.model.feature_extractor[0].out_features
                }
            }, self.model_path)
            
            self._report_progress(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {self.model_path}")
        else:
            self._report_progress("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å: –º–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
