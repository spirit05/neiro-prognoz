# [file name]: model/simple_system.py
"""
–ì–ª–∞–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –£–°–ò–õ–ï–ù–ù–û–ô –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ - –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù –î–õ–Ø WEB
"""

import os
import sys
from typing import List, Tuple

# –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—É—Ç–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ model
try:
    from .simple_nn.trainer import EnhancedTrainer
    from .simple_nn.predictor import EnhancedPredictor
    from .data_loader import load_dataset
except ImportError:
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –∏–º–ø–æ—Ä—Ç–∞
    from simple_nn.trainer import EnhancedTrainer
    from simple_nn.predictor import EnhancedPredictor
    from data_loader import load_dataset

class SimpleNeuralSystem:
    def __init__(self):
        self.model_path = "data/simple_model.pth"
        self.trainer = EnhancedTrainer(self.model_path)
        self.predictor = EnhancedPredictor(self.model_path)
        self.is_trained = False
        self.progress_callback = None
        self.ensemble_enabled = True
        
        # –õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –∏ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è
        self._full_ensemble = None
        self._self_learning = None
        
        self._auto_load_model()
    
    def _get_full_ensemble(self):
        """–õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã"""
        if self._full_ensemble is None:
            try:
                from .ensemble_predictor import EnsemblePredictor
                self._full_ensemble = EnsemblePredictor()
                print(f"üîç DEBUG: m/ss –∑–∞–≥—Ä—É—É–∑–∫–∞ –∞–Ω—Å —Å–∏—Å—Ç–µ–º—ã")
                if self.predictor.is_trained:
                    self._full_ensemble.set_neural_predictor(self.predictor)
                    self._update_full_ensemble()
            except ImportError as e:
                print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞–Ω—Å–∞–º–±–ª–µ–≤—É—é —Å–∏—Å—Ç–µ–º—É: {e}")
                self._full_ensemble = None
        return self._full_ensemble
    
    def _get_self_learning(self):
        """–õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º—ã —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è"""
        if self._self_learning is None:
            try:
                from .self_learning import SelfLearningSystem
                self._self_learning = SelfLearningSystem()
            except ImportError as e:
                print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–∏—Å—Ç–µ–º—É —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è: {e}")
                self._self_learning = None
        return self._self_learning
    
    def _auto_load_model(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
        if os.path.exists(self.model_path):
            if self.predictor.load_model():
                self.is_trained = True
                print("‚úÖ –£–°–ò–õ–ï–ù–ù–ê–Ø –º–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—ã –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
                self._get_full_ensemble()
                self._get_self_learning()
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")
        else:
            print("üìù –ú–æ–¥–µ–ª—å –µ—â–µ –Ω–µ –æ–±—É—á–µ–Ω–∞")
    
    def _update_full_ensemble(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è"""
        try:
            dataset = load_dataset()
            ensemble = self._get_full_ensemble()
            if ensemble:
                ensemble.update_ensemble(dataset)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è: {e}")
    
    def set_progress_callback(self, callback):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        self.progress_callback = callback
        if hasattr(self.trainer, 'set_progress_callback'):
            self.trainer.set_progress_callback(callback)
    
    def _report_progress(self, message):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ"""
        if self.progress_callback:
            self.progress_callback(message)
        else:
            print(f"üì¢ {message}")
    
    def train(self, epochs: int = 20) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–û–±—É—á–µ–Ω–∏–µ –£–°–ò–õ–ï–ù–ù–û–ô —Å–∏—Å—Ç–µ–º—ã —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º –ø—Ä–æ–≥–Ω–æ–∑–æ–≤"""
        groups = load_dataset()
        if not groups:
            self._report_progress("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return []
        
        if len(groups) < 50:
            self._report_progress(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(groups)} –≥—Ä—É–ø–ø (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 50)")
            return []
        
        self._report_progress(f"üß† –û–±—É—á–µ–Ω–∏–µ –£–°–ò–õ–ï–ù–ù–û–ô –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –Ω–∞ {len(groups)} –≥—Ä—É–ø–ø–∞—Ö...")
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º callback –≤ trainer
        if hasattr(self.trainer, 'set_progress_callback'):
            self.trainer.set_progress_callback(self.progress_callback)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –∏ –ø–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑—ã
        result = self.trainer.train(groups, epochs=epochs)
        self.is_trained = True
        
        # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
        self.predictor.load_model()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∞–Ω—Å–∞–º–±–ª—å
        self._update_full_ensemble()
        
        self._report_progress("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∏ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        return result
    
    def add_data_and_retrain(self, new_group: str, retrain_epochs: int = 5) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –£–°–ò–õ–ï–ù–ù–û–ô –º–æ–¥–µ–ª–∏ —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º –ø—Ä–æ–≥–Ω–æ–∑–æ–≤"""
        from data_loader import load_dataset, save_dataset, validate_group
        
        if not validate_group(new_group):
            self._report_progress("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≥—Ä—É–ø–ø—ã")
            return []
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        dataset = load_dataset()
        old_count = len(dataset)
        
        self._report_progress(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {old_count} –≥—Ä—É–ø–ø –∏–∑ dataset.json")
        
        dataset.append(new_group)
        save_dataset(dataset)
        
        new_count = len(dataset)
        self._report_progress(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ dataset.json ({new_count} –≥—Ä—É–ø–ø)")
        
        predictions = []
        
        # –í—Å–µ–≥–¥–∞ –æ–±–Ω–æ–≤–ª—è–µ–º –∞–Ω—Å–∞–º–±–ª—å
        self._update_full_ensemble()
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        learning_system = self._get_self_learning()
        if learning_system:
            learning_result = learning_system.analyze_prediction_accuracy(new_group)
            if learning_result:
                accuracy = learning_result['accuracy_score']
                matches = learning_result['matches_count']
                self._report_progress(f"üìä –ê–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏: {matches}/4 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π (—Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.1%})")
        
        # –î–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –æ–Ω–∞ —É–∂–µ –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ –∏ –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
        if self.is_trained and len(dataset) >= 50:
            self._report_progress("üîÑ –î–æ–æ–±—É—á–µ–Ω–∏–µ –£–°–ò–õ–ï–ù–ù–û–ô –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º callback –≤ trainer
            if hasattr(self.trainer, 'set_progress_callback'):
                self.trainer.set_progress_callback(self.progress_callback)
            
            self.trainer.train(dataset, epochs=retrain_epochs)
            self.predictor.load_model()
            self._report_progress("‚úÖ –ú–æ–¥–µ–ª—å –¥–æ–æ–±—É—á–µ–Ω–∞!")
            
            # –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ—Å–ª–µ –¥–æ–æ–±—É—á–µ–Ω–∏—è
            self._report_progress("üîÆ –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ—Å–ª–µ –¥–æ–æ–±—É—á–µ–Ω–∏—è...")
            predictions = self._make_prediction()
            
        elif not self.is_trained and len(dataset) >= 50:
            self._report_progress("üéØ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –£–°–ò–õ–ï–ù–ù–û–ô –º–æ–¥–µ–ª–∏!")
            predictions = self.train(epochs=20)
        else:
            # –î–∞–∂–µ –µ—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–æ–±—É—á–∞–µ–º, –¥–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω—Å–∞–º–±–ª—è
            self._report_progress("üîÆ –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è...")
            predictions = self._make_ensemble_prediction()
        
        return predictions
    
    def _make_prediction(self) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –£–°–ò–õ–ï–ù–ù–û–ô –º–æ–¥–µ–ª—å—é"""
        groups = load_dataset()
        if not groups:
            return []
        
        # –ü—Ä–æ–±—É–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å —Å–Ω–∞—á–∞–ª–∞
        if self.ensemble_enabled:
            try:
                print("üîç DEBUG: m/ss  –ü–æ–ª–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å –Ω–∞—á–∞–ª–æ")
                ensemble_predictions = self._make_ensemble_prediction()
                print(f"üîç DEBUG: m/ss  –ü–æ–ª–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å –∑–∞–∫–æ–Ω—á–µ–Ω –∏–¥–µ–º –¥–∞–ª—å—à–µ")
                if ensemble_predictions:
                    return ensemble_predictions
            except Exception as e:
                self._report_progress(f"‚ö†Ô∏è  –ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {e}")
        
        # –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç: –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞
        recent_numbers = []
        for group_str in groups[-25:]:
            try:
                numbers = [int(x) for x in group_str.strip().split()]
                if len(numbers) == 4:
                    recent_numbers.extend(numbers)
            except:
                continue
        
        if len(recent_numbers) < 50:
            self._report_progress("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
            return []
        
        predictions = self.predictor.predict_group(recent_numbers, 15)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º —Å–ª–∞–±—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        filtered_predictions = [(group, score) for group, score in predictions if score > 0.0005]
        if not filtered_predictions:
            self._report_progress("‚ö†Ô∏è  –í—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–º–µ—é—Ç –Ω–∏–∑–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
            best_predictions = sorted(predictions, key=lambda x: x[1], reverse=True)[:4]
            return best_predictions
        
        return filtered_predictions[:4]
    
    def _make_ensemble_prediction(self) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–ü—Ä–æ–≥–Ω–æ–∑ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–æ–ª–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è"""
        groups = load_dataset()
        if not groups:
            return []
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è
        recent_numbers = []
        for group_str in groups[-30:]:
            try:
                numbers = [int(x) for x in group_str.strip().split()]
                if len(numbers) == 4:
                    recent_numbers.extend(numbers)
            except:
                continue

        print(f"üîç DEBUG: m/ss –∏—Å—Ç–æ—Ä–∏—è –∞–Ω—Å–∞–º–±–ª—è {len(recent_numbers)}")
        
        if len(recent_numbers) < 40:
            self._report_progress("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
            return []
        
        try:
            ensemble = self._get_full_ensemble()
            if ensemble:
                print(f"üîç DEBUG:m/ss  –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞—á–∞–ª–æ")
                predictions = ensemble.predict_ensemble(recent_numbers, 10)
                print(f"üîç DEBUG: m/ss –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∫–æ–Ω–µ—Ü - –∫–æ–ª-–≤–æ {len(predictions)}")
                if predictions:
                    self._report_progress(f"üéØ –ü–æ–ª–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª {len(predictions)} –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
                    return predictions[:4]
        except Exception as e:
            self._report_progress(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è: {e}")
        
        return []
    
    def load(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        success = self.predictor.load_model()
        self.is_trained = success
        
        if success:
            self._update_full_ensemble()
        
        return success
    
    def predict(self, top_k: int = 10) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≥—Ä—É–ø–ø –£–°–ò–õ–ï–ù–ù–û–ô –º–æ–¥–µ–ª—å—é"""
        if not self.is_trained:
            if not self.load():
                self._report_progress("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                return []
        
        return self._make_prediction()
    
    def get_status(self) -> dict:
        """–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"""
        dataset = load_dataset()
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–Ω—Å–∞–º–±–ª–µ –∏ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–∏
        ensemble_info = {
            'ensemble_enabled': self.ensemble_enabled,
            'ensemble_available': self._get_full_ensemble() is not None,
            'dataset_size_for_ensemble': len(dataset)
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è
        learning_stats = {}
        learning_system = self._get_self_learning()
        if learning_system:
            learning_stats = learning_system.get_performance_stats()
        
        return {
            'is_trained': self.is_trained,
            'model_loaded': self.predictor.is_trained,
            'model_path': self.predictor.model_path,
            'dataset_size': len(dataset),
            'has_sufficient_data': len(dataset) >= 50,
            'model_type': '–£–°–ò–õ–ï–ù–ù–ê–Ø –Ω–µ–π—Ä–æ—Å–µ—Ç—å —Å –∞–Ω—Å–∞–º–±–ª–µ–º –∏ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ–º',
            'ensemble_info': ensemble_info,
            'learning_stats': learning_stats
        }
    
    def get_learning_insights(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø–æ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—é"""
        learning_system = self._get_self_learning()
        if learning_system:
            return learning_system.get_performance_stats()
        return {'message': '–°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞'}
    
    def reset_learning_data(self):
        """–°–±—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è"""
        learning_system = self._get_self_learning()
        if learning_system:
            learning_system.reset_learning_data()
            self._report_progress("‚úÖ –î–∞–Ω–Ω—ã–µ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è —Å–±—Ä–æ—à–µ–Ω—ã")
        else:
            self._report_progress("‚ùå –°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞")
