# model/simple_system.py
"""
–ì–ª–∞–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –£–°–ò–õ–ï–ù–ù–û–ô –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
"""

import os
import sys
from typing import List, Tuple

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from model.simple_nn.trainer import EnhancedTrainer
from model.simple_nn.predictor import EnhancedPredictor
from model.data_loader import load_dataset

class SimpleNeuralSystem:
    def __init__(self):
        self.model_path = "data/simple_model.pth"
        self.trainer = EnhancedTrainer(self.model_path)
        self.predictor = EnhancedPredictor(self.model_path)
        self.is_trained = False
        self.progress_callback = None  # –î–æ–±–∞–≤–ª—è–µ–º callback
        self._auto_load_model()
    
    def set_progress_callback(self, callback):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        self.progress_callback = callback
        if hasattr(self.trainer, 'set_progress_callback'):
            self.trainer.set_progress_callback(callback)
    
    def _report_progress(self, message):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ"""
        if self.progress_callback:
            self.progress_callback(message)

    def _auto_load_model(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
        if os.path.exists(self.model_path):
            if self.predictor.load_model():
                self.is_trained = True
                print("‚úÖ –£–°–ò–õ–ï–ù–ù–ê–Ø –º–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")
        else:
            print("üìù –ú–æ–¥–µ–ª—å –µ—â–µ –Ω–µ –æ–±—É—á–µ–Ω–∞")
    
    def add_data_and_retrain(self, new_group: str, retrain_epochs: int = 10) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ –¥–æ–æ–±—É—á–µ–Ω–∏–µ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º"""
        from model.data_loader import load_dataset, save_dataset, validate_group
        
        if not validate_group(new_group):
            self._report_progress("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≥—Ä—É–ø–ø—ã")
            return []
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        dataset = load_dataset()
        old_count = len(dataset)
        
        self._report_progress(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {old_count} –≥—Ä—É–ø–ø –∏–∑ dataset.json")
        
        dataset.append(new_group)
        save_dataset(dataset)
        
        new_count = len(dataset)
        self._report_progress(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ dataset.json ({new_count} –≥—Ä—É–ø–ø)")
        self._report_progress(f"‚úÖ –ì—Ä—É–ø–ø–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞. –í—Å–µ–≥–æ –≥—Ä—É–ø–ø: {new_count}")
        
        predictions = []
        
        # –î–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –æ–Ω–∞ —É–∂–µ –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ –∏ –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
        if self.is_trained and len(dataset) >= 50:
            self._report_progress("üîÑ –î–æ–æ–±—É—á–µ–Ω–∏–µ –£–°–ò–õ–ï–ù–ù–û–ô –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º callback –≤ trainer
            if hasattr(self.trainer, 'set_progress_callback'):
                self.trainer.set_progress_callback(self.progress_callback)
            
            self.trainer.train(dataset, epochs=retrain_epochs)
            self.predictor.load_model()
            self._report_progress("‚úÖ –ú–æ–¥–µ–ª—å –¥–æ–æ–±—É—á–µ–Ω–∞!")
            
            # –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ—Å–ª–µ –¥–æ–æ–±—É—á–µ–Ω–∏—è
            self._report_progress("üîÆ –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ—Å–ª–µ –¥–æ–æ–±—É—á–µ–Ω–∏—è...")
            predictions = self._make_prediction()
            
        elif not self.is_trained and len(dataset) >= 50:
            self._report_progress("üéØ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è!")
            predictions = self.train(epochs=20)
        
        return predictions
    
    def train(self, epochs: int = 25) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–û–±—É—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º"""
        groups = load_dataset()
        if not groups:
            self._report_progress("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return []
        
        if len(groups) < 50:
            self._report_progress(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(groups)} –≥—Ä—É–ø–ø")
            return []
        
        self._report_progress(f"üß† –û–±—É—á–µ–Ω–∏–µ –£–°–ò–õ–ï–ù–ù–û–ô –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –Ω–∞ {len(groups)} –≥—Ä—É–ø–ø–∞—Ö...")
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º callback –≤ trainer
        if hasattr(self.trainer, 'set_progress_callback'):
            self.trainer.set_progress_callback(self.progress_callback)
        
        self.trainer.train(groups, epochs=epochs)
        self.is_trained = True
        self.predictor.load_model()
        self._report_progress("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∏ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        
        # –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
        self._report_progress("üîÆ –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è...")
        predictions = self._make_prediction()
        return predictions
    
    def _make_prediction(self) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –£–°–ò–õ–ï–ù–ù–û–ô –º–æ–¥–µ–ª—å—é"""
        groups = load_dataset()
        if not groups:
            return []
        
        # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        recent_numbers = []
        for group_str in groups[-25:]:  # –£–≤–µ–ª–∏—á–∏–ª–∏ –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è —É—Å–∏–ª–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            try:
                numbers = [int(x) for x in group_str.strip().split()]
                if len(numbers) == 4:
                    recent_numbers.extend(numbers)
            except:
                continue
        
        if len(recent_numbers) < 50:  # –£–≤–µ–ª–∏—á–∏–ª–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é
            print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
            return []
        
        predictions = self.predictor.predict_group(recent_numbers, 15)  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º —Å–ª–∞–±—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        filtered_predictions = [(group, score) for group, score in predictions if score > 0.0005]  # –ü–æ–≤—ã—Å–∏–ª–∏ –ø–æ—Ä–æ–≥
        
        if not filtered_predictions:
            print("‚ö†Ô∏è  –í—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–º–µ—é—Ç –Ω–∏–∑–∫—É—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-4 –¥–∞–∂–µ –µ—Å–ª–∏ —Å–ª–∞–±—ã–µ, –Ω–æ —Å –ª—É—á—à–∏–º–∏ score
            best_predictions = sorted(predictions, key=lambda x: x[1], reverse=True)[:4]
            return best_predictions
        
        return filtered_predictions[:4]
    
    def load(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        success = self.predictor.load_model()
        self.is_trained = success
        return success
    
    def predict(self, top_k: int = 10) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≥—Ä—É–ø–ø –£–°–ò–õ–ï–ù–ù–û–ô –º–æ–¥–µ–ª—å—é"""
        if not self.is_trained:
            if not self.load():
                print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ –∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                return []
        
        return self._make_prediction()
    
    def get_status(self) -> dict:
        """–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"""
        dataset = load_dataset()
        return {
            'is_trained': self.is_trained,
            'model_loaded': self.predictor.is_trained,
            'model_path': self.predictor.model_path,
            'dataset_size': len(dataset),
            'has_sufficient_data': len(dataset) >= 50,
            'model_type': '–£–°–ò–õ–ï–ù–ù–ê–Ø –Ω–µ–π—Ä–æ—Å–µ—Ç—å'
        }