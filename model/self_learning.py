# [file name]: model/self_learning.py
"""
–°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—à–∏–±–∫–∞—Ö
"""

import json
import os
from typing import List, Tuple, Dict
from datetime import datetime
from .data_loader import load_dataset, load_predictions, compare_groups

class SelfLearningSystem:
    def __init__(self, results_file: str = "data/learning_results.json"):
        self.results_file = results_file
        self.learning_data = self._load_learning_data()
    
    def _load_learning_data(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è"""
        if os.path.exists(self.results_file):
            try:
                with open(self.results_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        return {
            'predictions_accuracy': [],
            'model_performance': {},
            'learning_patterns': {},
            'last_analysis': None
        }
    
    def analyze_prediction_accuracy(self, actual_group: str):
        """–ê–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        try:
            actual_numbers = [int(x) for x in actual_group.strip().split()]
            actual_tuple = tuple(actual_numbers)
            
            previous_predictions = load_predictions()
            if not previous_predictions:
                return None
            
            best_match = None
            best_score = 0
            best_prediction = None
            
            # –ò—â–µ–º –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å—Ä–µ–¥–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            for pred_group, score in previous_predictions:
                comparison = compare_groups(pred_group, actual_tuple)
                total_matches = comparison['total_matches']
                
                if total_matches > best_score:
                    best_score = total_matches
                    best_match = comparison
                    best_prediction = pred_group
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            analysis_result = {
                'timestamp': datetime.now().isoformat(),
                'actual_group': actual_group,
                'best_prediction': best_prediction,
                'matches_count': best_score,
                'comparison_details': best_match,
                'accuracy_score': best_score / 4.0  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
            }
            
            self.learning_data['predictions_accuracy'].append(analysis_result)
            self._save_learning_data()
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫
            self._analyze_error_patterns(analysis_result)
            
            return analysis_result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏: {e}")
            return None
    
    def _analyze_error_patterns(self, analysis_result: Dict):
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ—à–∏–±–æ–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        accuracy = analysis_result['accuracy_score']
        
        if accuracy < 0.5:  # –ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
            actual_group = analysis_result['actual_group']
            predicted_group = analysis_result['best_prediction']
            
            if predicted_group:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º, –∫–∞–∫–∏–µ —á–∏—Å–ª–∞ –±—ã–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω—ã
                actual_numbers = [int(x) for x in actual_group.split()]
                predicted_numbers = list(predicted_group)
                
                missed_numbers = set(actual_numbers) - set(predicted_numbers)
                false_numbers = set(predicted_numbers) - set(actual_numbers)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫
                if 'error_patterns' not in self.learning_data:
                    self.learning_data['error_patterns'] = []
                
                error_pattern = {
                    'timestamp': analysis_result['timestamp'],
                    'missed_numbers': list(missed_numbers),
                    'false_numbers': list(false_numbers),
                    'accuracy': accuracy
                }
                
                self.learning_data['error_patterns'].append(error_pattern)
    
    def get_learning_recommendations(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫"""
        recommendations = []
        
        # –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç—ã—Ö –æ—à–∏–±–æ–∫
        if 'error_patterns' in self.learning_data:
            error_patterns = self.learning_data['error_patterns'][-20:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 20 –æ—à–∏–±–æ–∫
            
            # –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º—ã—Ö —á–∏—Å–µ–ª
            missed_counter = {}
            for pattern in error_patterns:
                for num in pattern.get('missed_numbers', []):
                    missed_counter[num] = missed_counter.get(num, 0) + 1
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞
            if missed_counter:
                most_missed = max(missed_counter, key=missed_counter.get)
                recommendations.append(f"‚ö†Ô∏è  –ß–∞—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —á–∏—Å–ª–æ {most_missed} - —É–≤–µ–ª–∏—á—å—Ç–µ –µ–≥–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç")
        
        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        accuracy_data = self.learning_data.get('predictions_accuracy', [])
        if accuracy_data:
            recent_accuracy = [a['accuracy_score'] for a in accuracy_data[-10:]]
            if recent_accuracy:
                avg_accuracy = sum(recent_accuracy) / len(recent_accuracy)
                
                if avg_accuracy < 0.3:
                    recommendations.append("üéØ –ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")
                elif avg_accuracy > 0.7:
                    recommendations.append("‚úÖ –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å - —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ!")
        
        if not recommendations:
            recommendations.append("üìä –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")
        
        return recommendations
    
    def adjust_ensemble_weights(self, ensemble_predictor) -> bool:
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –≤–µ—Å–æ–≤ –∞–Ω—Å–∞–º–±–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            accuracy_data = self.learning_data.get('predictions_accuracy', [])
            if len(accuracy_data) < 5:  # –ù—É–∂–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
                return False
            
            # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
            recent_accuracy = accuracy_data[-10:]
            accuracy_scores = [a['accuracy_score'] for a in recent_accuracy if 'accuracy_score' in a]
            
            if not accuracy_scores:
                return False
                
            avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)
            
            if avg_accuracy < 0.4:
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
                if hasattr(ensemble_predictor, 'weights') and 'neural' in ensemble_predictor.weights:
                    ensemble_predictor.weights['neural'] = min(0.5, ensemble_predictor.weights['neural'] + 0.1)
                    if 'frequency' in ensemble_predictor.weights:
                        ensemble_predictor.weights['frequency'] = max(0.2, ensemble_predictor.weights['frequency'] - 0.05)
                    print("üîß –°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤–µ—Å–∞ –∞–Ω—Å–∞–º–±–ª—è –≤ –ø–æ–ª—å–∑—É –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
                    return True
                
            return False
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –≤–µ—Å–æ–≤: {e}")
            return False
    
    def _save_learning_data(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è"""
        try:
            os.makedirs(os.path.dirname(self.results_file), exist_ok=True)
            self.learning_data['last_analysis'] = datetime.now().isoformat()
            
            with open(self.results_file, 'w', encoding='utf-8') as f:
                json.dump(self.learning_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è: {e}")
    
    def get_performance_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        accuracy_data = self.learning_data.get('predictions_accuracy', [])
        
        if not accuracy_data:
            return {'message': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'}
        
        recent_accuracy = [a.get('accuracy_score', 0) for a in accuracy_data[-20:] if 'accuracy_score' in a]
        
        if not recent_accuracy:
            return {'message': '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞'}
        
        return {
            'total_predictions_analyzed': len(accuracy_data),
            'recent_accuracy_avg': sum(recent_accuracy) / len(recent_accuracy),
            'best_accuracy': max(recent_accuracy),
            'worst_accuracy': min(recent_accuracy),
            'recommendations': self.get_learning_recommendations()
        }
    
    def reset_learning_data(self):
        """–°–±—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è"""
        self.learning_data = {
            'predictions_accuracy': [],
            'model_performance': {},
            'learning_patterns': {},
            'last_analysis': None
        }
        self._save_learning_data()
        print("‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–∏—è —Å–±—Ä–æ—à–µ–Ω—ã")