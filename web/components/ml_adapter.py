# [file name]: web/components/ml_adapter.py
"""
–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤–µ–±-—Å–µ—Ä–≤–∏—Å–∞ —Å –Ω–æ–≤–æ–π –º–æ–¥—É–ª—å–Ω–æ–π ML –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
"""

import sys
import os
from typing import List, Tuple, Dict
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
sys.path.insert(0, '/opt/dev')

from config import paths, constants, logging_config

logger = logging_config.get_ml_system_logger()

class MLSystemAdapter:
    """–ì–ª–∞–≤–Ω—ã–π –∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –Ω–æ–≤–æ–π –º–æ–¥—É–ª—å–Ω–æ–π ML —Å–∏—Å—Ç–µ–º–æ–π - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
    
    def __init__(self):
        self.is_trained = False
        self.progress_callback = None
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        self.trainer = None
        self.predictor = None
        self.self_learning = None
        self.ensemble = None
        self.data_processor = None
        
        self._initialize_new_architecture()
    
    def _initialize_new_architecture(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–æ–≤–æ–π –º–æ–¥—É–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã - –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –ò–ú–ü–û–†–¢–´"""
        try:
            # ‚ö° –ü–†–ê–í–ò–õ–¨–ù–´–ï –ò–ú–ü–û–†–¢–´ –∏–∑ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
            from ml.core.trainer import EnhancedTrainer
            from ml.core.predictor import EnhancedPredictor
            from ml.learning.self_learning import SelfLearningSystem
            from ml.core.data_processor import DataProcessor
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–Ω–µ—Ä–∞
            self.trainer = EnhancedTrainer()
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—è
            self.predictor = EnhancedPredictor()
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è
            self.self_learning = SelfLearningSystem()
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
            self.data_processor = DataProcessor()
            
            # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å
            self._auto_load_model()
            
            logger.info("‚úÖ MLSystemAdapter —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π")
            
        except ImportError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã: {e}")
            # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            self._create_mock_components()
    
    def _create_mock_components(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ mock –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö –∏–º–ø–æ—Ä—Ç–∞"""
        class MockTrainer:
            def set_progress_callback(self, callback): pass
            def train(self, groups, epochs=None): return []
        
        class MockPredictor:
            def __init__(self): self.is_trained = False
            def load_model(self): return False
            def predict_group(self, history, top_k=None): return []
        
        class MockSelfLearning:
            def analyze_prediction_accuracy(self, actual_group): return None
            def get_performance_stats(self): return {'message': 'Mock system'}
        
        self.trainer = MockTrainer()
        self.predictor = MockPredictor()
        self.self_learning = MockSelfLearning()
        logger.info("‚ö†Ô∏è  –°–æ–∑–¥–∞–Ω—ã mock –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    def _auto_load_model(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if self.predictor and hasattr(self.predictor, 'load_model'):
            if self.predictor.load_model():
                self.is_trained = True
                logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã")
            else:
                logger.info("üìù –ú–æ–¥–µ–ª—å –µ—â–µ –Ω–µ –æ–±—É—á–µ–Ω–∞ –≤ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ")
    
    def set_progress_callback(self, callback):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        self.progress_callback = callback
        if self.trainer and hasattr(self.trainer, 'set_progress_callback'):
            self.trainer.set_progress_callback(callback)
    
    def _report_progress(self, message):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ"""
        logger.info(message)
        if self.progress_callback:
            self.progress_callback(message)
    
    def train(self, epochs: int = None) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ"""
        if epochs is None:
            epochs = constants.MAIN_TRAINING_EPOCHS
            
        from ml.utils.data_utils import load_dataset
        groups = load_dataset()
        
        if not groups:
            self._report_progress("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return []
        
        if len(groups) < constants.MIN_DATASET_SIZE:
            self._report_progress(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(groups)} –≥—Ä—É–ø–ø (–Ω—É–∂–Ω–æ {constants.MIN_DATASET_SIZE})")
            return []
        
        self._report_progress(f"üß† –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ {len(groups)} –≥—Ä—É–ø–ø–∞—Ö...")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –Ω–æ–≤–æ–≥–æ —Ç—Ä–µ–Ω–µ—Ä–∞
        if self.trainer and hasattr(self.trainer, 'train'):
            predictions = self.trainer.train(groups, epochs=epochs)
            
            if predictions:
                self.is_trained = True
                # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
                if self.predictor and hasattr(self.predictor, 'load_model'):
                    self.predictor.load_model()
                self._report_progress(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(predictions)} –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
            else:
                self._report_progress("‚ö†Ô∏è –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –Ω–æ –ø—Ä–æ–≥–Ω–æ–∑—ã –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã")
            
            return predictions
        else:
            self._report_progress("‚ùå –¢—Ä–µ–Ω–µ—Ä –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
            return []
    
    def predict(self, top_k: int = None) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ"""
        if top_k is None:
            top_k = constants.PREDICTION_TOP_K
            
        if not self.is_trained:
            self._report_progress("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
            return []
        
        from ml.utils.data_utils import load_dataset
        groups = load_dataset()
        
        if not groups:
            self._report_progress("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")
            return []
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        recent_numbers = []
        for group_str in groups[-25:]:  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 25 –≥—Ä—É–ø–ø
            try:
                numbers = [int(x) for x in group_str.strip().split()]
                if len(numbers) == 4:
                    recent_numbers.extend(numbers)
            except:
                continue
        
        if len(recent_numbers) < 50:
            self._report_progress("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
            return []
        
        self._report_progress("üîÆ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤...")
        
        if self.predictor and hasattr(self.predictor, 'predict_group'):
            predictions = self.predictor.predict_group(recent_numbers, top_k)
            
            if predictions:
                self._report_progress(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(predictions)} –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
            else:
                self._report_progress("‚ö†Ô∏è –ü—Ä–æ–≥–Ω–æ–∑—ã –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã")
            
            return predictions
        else:
            self._report_progress("‚ùå –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
            return []
    
    def add_data_and_retrain(self, sequence_input: str, retrain_epochs: int = None) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –≤ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ"""
        if retrain_epochs is None:
            retrain_epochs = constants.RETRAIN_EPOCHS
            
        from ml.utils.data_utils import load_dataset, save_dataset, validate_group
        
        if not validate_group(sequence_input):
            self._report_progress("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≥—Ä—É–ø–ø—ã")
            return []
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        dataset = load_dataset()
        old_count = len(dataset)
        
        dataset.append(sequence_input)
        save_dataset(dataset)
        
        new_count = len(dataset)
        self._report_progress(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {old_count} ‚Üí {new_count} –≥—Ä—É–ø–ø")
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
        if self.self_learning and hasattr(self.self_learning, 'analyze_prediction_accuracy'):
            analysis_result = self.self_learning.analyze_prediction_accuracy(sequence_input)
            if analysis_result:
                accuracy = analysis_result['accuracy_score']
                matches = analysis_result['matches_count']
                self._report_progress(f"üìä –ê–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏: {matches}/4 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π (—Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.1%})")
        
        predictions = []
        
        # –î–æ–æ–±—É—á–µ–Ω–∏–µ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —É–∂–µ –æ–±—É—á–µ–Ω–∞ –∏ –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
        if self.is_trained and len(dataset) >= constants.MIN_DATASET_SIZE:
            self._report_progress("üîÑ –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            
            if self.trainer and hasattr(self.trainer, 'train'):
                predictions = self.trainer.train(dataset, epochs=retrain_epochs)
                
                if predictions:
                    if self.predictor and hasattr(self.predictor, 'load_model'):
                        self.predictor.load_model()
                    self._report_progress("‚úÖ –ú–æ–¥–µ–ª—å –¥–æ–æ–±—É—á–µ–Ω–∞!")
                else:
                    self._report_progress("‚ö†Ô∏è –î–æ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –Ω–æ –ø—Ä–æ–≥–Ω–æ–∑—ã –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã")
                    
        elif not self.is_trained and len(dataset) >= constants.MIN_DATASET_SIZE:
            self._report_progress("üéØ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è!")
            predictions = self.train(epochs=constants.MAIN_TRAINING_EPOCHS)
        else:
            # –ï—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–æ–±—É—á–∞–µ–º, –¥–µ–ª–∞–µ–º –æ–±—ã—á–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑
            self._report_progress("üîÆ –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
            predictions = self.predict()
        
        return predictions
    
    def get_status(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã –∏–∑ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã"""
        from ml.utils.data_utils import load_dataset
        dataset = load_dataset()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è
        learning_stats = {}
        if self.self_learning and hasattr(self.self_learning, 'get_performance_stats'):
            learning_stats = self.self_learning.get_performance_stats()
        
        return {
            'is_trained': self.is_trained,
            'model_loaded': self.predictor.is_trained if self.predictor and hasattr(self.predictor, 'is_trained') else False,
            'dataset_size': len(dataset),
            'has_sufficient_data': len(dataset) >= constants.MIN_DATASET_SIZE,
            'model_type': '–ú–û–î–£–õ–¨–ù–ê–Ø –£–°–ò–õ–ï–ù–ù–ê–Ø –ù–ï–ô–†–û–°–ï–¢–¨',
            'learning_stats': learning_stats,
            'architecture': '–ù–û–í–ê–Ø –ú–û–î–£–õ–¨–ù–ê–Ø (ml/)'
        }
    
    def get_learning_insights(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è"""
        if self.self_learning and hasattr(self.self_learning, 'get_performance_stats'):
            return self.self_learning.get_performance_stats()
        return {'message': '–°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞'}
    
    def load(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        if self.predictor and hasattr(self.predictor, 'load_model'):
            success = self.predictor.load_model()
            self.is_trained = success
            return success
        return False

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
def create_ml_system():
    """–°–æ–∑–¥–∞–Ω–∏–µ ML —Å–∏—Å—Ç–µ–º—ã (–∑–∞–º–µ–Ω–∞ SimpleNeuralSystem)"""
    return MLSystemAdapter()

