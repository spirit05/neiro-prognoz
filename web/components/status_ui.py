# [file name]: web/components/status_ui.py
"""
–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å—Ç–∞—Ç—É—Å–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
"""

import streamlit as st
from ml.utils.data_utils import load_predictions, load_dataset

def show_status_ui(system):
    """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å—Ç–∞—Ç—É—Å–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
    st.header("üìä –û–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞")
    
    if not system:
        st.error("‚ùå –°–∏—Å—Ç–µ–º–∞ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        return
    
    try:
        # –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
        status = system.get_status()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üß† –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏")
            if status['is_trained']:
                st.success("‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")
            else:
                st.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
            
            st.info(f"üìÅ –ì—Ä—É–ø–ø –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ: {status['dataset_size']}")
            
            if status['has_sufficient_data']:
                st.success("‚úÖ –î–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ")
            else:
                st.warning(f"‚ö†Ô∏è –ù—É–∂–Ω–æ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö (–º–∏–Ω–∏–º—É–º 50)")
        
        with col2:
            st.subheader("üîß –°–∏—Å—Ç–µ–º–∞")
            st.info(f"üéØ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {status.get('architecture', '–ú–û–î–£–õ–¨–ù–ê–Ø')}")
            st.info(f"üèóÔ∏è –¢–∏–ø: {status.get('model_type', '–£–°–ò–õ–ï–ù–ù–ê–Ø –ù–ï–ô–†–û–°–ï–¢–¨')}")
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑—ã
        st.subheader("üéØ –ü–æ—Å–ª–µ–¥–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑—ã")
        predictions = load_predictions()
        if predictions:
            for i, (group, score) in enumerate(predictions[:4], 1):
                confidence = "üü¢ –í–´–°–û–ö–ê–Ø" if score > 0.01 else "üü° –°–†–ï–î–ù–Ø–Ø" if score > 0.001 else "üî¥ –ù–ò–ó–ö–ê–Ø"
                st.write(f"**{i}.** `{group[0]} {group[1]} {group[2]} {group[3]}` - —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: `{score:.6f}` {confidence}")
        else:
            st.info("üìù –ü—Ä–æ–≥–Ω–æ–∑—ã –µ—â–µ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã")
        
        # –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è
        st.subheader("üìà –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è")
        learning_stats = system.get_learning_insights()
        
        if 'message' in learning_stats:
            st.info(learning_stats['message'])
        else:
            col1, col2 = st.columns(2)
            with col1:
                if 'recent_accuracy_avg' in learning_stats:
                    accuracy = learning_stats['recent_accuracy_avg']
                    st.metric("üéØ –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å", f"{accuracy:.1%}")
                if 'total_predictions_analyzed' in learning_stats:
                    st.metric("üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤", learning_stats['total_predictions_analyzed'])
            
            with col2:
                if 'best_accuracy' in learning_stats:
                    best = learning_stats['best_accuracy']
                    st.metric("üèÜ –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å", f"{best:.1%}")
                if 'worst_accuracy' in learning_stats:
                    worst = learning_stats['worst_accuracy']
                    st.metric("üìâ –•—É–¥—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å", f"{worst:.1%}")
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if 'recommendations' in learning_stats and learning_stats['recommendations']:
                st.subheader("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
                for rec in learning_stats['recommendations']:
                    st.write(f"‚Ä¢ {rec}")
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")