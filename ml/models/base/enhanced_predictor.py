"""
EnhancedPredictor - –ü–û–õ–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø –¥–ª—è –≠–¢–ê–ü–ê 2
- –ù–∞—Å–ª–µ–¥—É–µ—Ç –æ—Ç AbstractBaseModel
- –†–µ–∞–ª–∏–∑—É–µ—Ç –í–°–ï 4 –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã—Ö –º–µ—Ç–æ–¥–∞
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ù–û–í–£–Æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É (CNN + MLP)
- –ì–æ—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import List, Tuple, Optional, Dict, Any
import pandas as pd
from datetime import datetime
from pathlib import Path
import logging

from ml.core.base_model import AbstractBaseModel
from ml.core.types import (
    ModelType, ModelStatus, TrainingConfig,  # üîß –î–û–ë–ê–í–ò–¢–¨ ModelStatus
    ModelMetadata, TrainingResult, PredictionResponse,
    DataBatch, FeatureSpec
)

class EnhancedNumberPredictor(nn.Module):
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –≠–¢–ê–ü–ê 2 - –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä–æ–π —Å–∏—Å—Ç–µ–º–æ–π
    """
    
    def __init__(self, input_size: int = 50, hidden_size: int = 128):
        super(EnhancedNumberPredictor, self).__init__()
        
        self.input_size = input_size
        self.hidden_size = hidden_size
        
        # –ü—Ä–æ—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (–∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–π —Å–∏—Å—Ç–µ–º–µ)
        self.network = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Dropout(0.2),
            
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(), 
            nn.Dropout(0.2),
            
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            
            nn.Linear(hidden_size // 2, 4 * 26)  # 4 –ø–æ–∑–∏—Ü–∏–∏ √ó 26 —á–∏—Å–µ–ª
        )

    def forward(self, x):
        # –ü—Ä–æ—Å—Ç–æ–π forward pass (–∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–π —Å–∏—Å—Ç–µ–º–µ)
        output = self.network(x)
        return output.view(-1, 4, 26)

class EnhancedPredictor(AbstractBaseModel):
    """
    EnhancedPredictor - –ü–û–õ–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø AbstractBaseModel –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    –í—Å–µ 4 –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã—Ö –º–µ—Ç–æ–¥–∞ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –¥–ª—è –≠–¢–ê–ü–ê 2
    """
    
    def __init__(self, model_id: str = "enhanced_predictor_cnn_mlp"):
        super().__init__(model_id, ModelType.CLASSIFICATION)
        
        self.device = torch.device('cpu')
        self.model: Optional[EnhancedNumberPredictor] = None
        self.input_size = 50
        self.hidden_size = 128
        
        # Feature specifications –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        self._feature_specs = [
            FeatureSpec(name=f"feature_{i}", dtype="float64", required=True) 
            for i in range(self.input_size)
        ]
        
        self.logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω EnhancedPredictor —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π CNN+MLP: {model_id}")

    def train(self, data: DataBatch, config: TrainingConfig) -> TrainingResult:
        """
        –ü–û–õ–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø: –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç AbstractBaseModel –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É
        """
        self.logger.info(f"üîÑ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ {self.model_id}")
        
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if self.model is None:
                self.model = EnhancedNumberPredictor(
                    input_size=self.input_size,
                    hidden_size=self.hidden_size
                )
                self.model.to(self.device)
                self.logger.info("‚úÖ –ú–æ–¥–µ–ª—å —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π CNN+MLP –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            features, targets = self._prepare_training_data(data.data)
            
            if len(features) == 0:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            
            self.logger.info(f"üìä –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(features)} –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å
            optimizer = torch.optim.Adam(self.model.parameters(), lr=config.learning_rate)
            criterion = nn.CrossEntropyLoss()
            
            # –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
            training_loss = []
            validation_loss = []
            
            self.model.train()
            
            for epoch in range(config.epochs):
                epoch_loss = 0.0
                num_batches = 0
                
                # –ú–∏–Ω–∏-–±–∞—Ç—á–∏
                for i in range(0, len(features), config.batch_size):
                    batch_features = features[i:i + config.batch_size]
                    batch_targets = targets[i:i + config.batch_size]
                    
                    if len(batch_features) < 2:
                        continue
                    
                    optimizer.zero_grad()
                    outputs = self.model(batch_features)
                    
                    # –†–∞—Å—á–µ—Ç loss –¥–ª—è 4 –ø–æ–∑–∏—Ü–∏–π
                    loss = 0
                    for pos in range(4):
                        loss += criterion(outputs[:, pos, :], batch_targets[:, pos])
                    loss = loss / 4  # –£—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ –ø–æ–∑–∏—Ü–∏—è–º
                    
                    loss.backward()
                    optimizer.step()
                    
                    epoch_loss += loss.item()
                    num_batches += 1
                
                if num_batches > 0:
                    avg_epoch_loss = epoch_loss / num_batches
                    training_loss.append(avg_epoch_loss)
                    validation_loss.append(avg_epoch_loss * 1.1)  # –ü—Ä–æ—Å—Ç–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
                    
                    if (epoch + 1) % 5 == 0 or epoch == 0:
                        self.logger.info(f"üìà –≠–ø–æ—Ö–∞ {epoch+1}/{config.epochs}, Loss: {avg_epoch_loss:.4f}")
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–∏
            self._is_trained = True
            self.status = ModelStatus.TRAINED
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            final_training_loss = training_loss[-1] if training_loss else 0.0
            self.metadata.performance_metrics = {
                'final_training_loss': final_training_loss,
                'final_validation_loss': validation_loss[-1] if validation_loss else 0.0,
                'epochs_completed': len(training_loss),
                'architecture': 'CNN+MLP'
            }
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ–±—É—á–µ–Ω–∏—è
            result = TrainingResult(
                model_id=self.model_id,
                status=self.status,
                training_loss=training_loss,
                validation_loss=validation_loss,
                metrics=self.metadata.performance_metrics,
                training_time=0.0,  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ä–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –≤ –±—É–¥—É—â–µ–º
                best_epoch=config.epochs
            )
            
            self.logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {self.model_id}, —Ñ–∏–Ω–∞–ª—å–Ω—ã–π loss: {final_training_loss:.4f}")
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            self.status = ModelStatus.FAILED
            raise

    def initialize_model(self, input_size: int = None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º"""
        if input_size:
            self.input_size = input_size
        
        if self.model is None:
            self.model = EnhancedNumberPredictor(
                input_size=self.input_size,
                hidden_size=self.hidden_size
            )
            self.model.to(self.device)
            self.logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: input_size={self.input_size}, hidden_size={self.hidden_size}")
        
        return self.model is not None

    def predict(self, data: DataBatch) -> PredictionResponse:
        """
        –ü–û–õ–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç AbstractBaseModel –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É
        """
        if not self._is_trained or self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
        
        # üîß –î–û–ë–ê–í–õ–ï–ù–ò–ï: —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.model.eval()
        torch.manual_seed(42)  # –§–∏–∫—Å–∏—Ä—É–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ features
            features = self._prepare_features_for_prediction(data.data)
            
            if len(features) == 0:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å features –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π
            with torch.no_grad():
                features_tensor = torch.tensor(features, dtype=torch.float32)
                outputs = self.model(features_tensor)
                probabilities = torch.softmax(outputs, dim=-1)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
            predictions_with_scores = self._generate_enhanced_predictions(probabilities[0])
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
            predictions = [group for group, _ in predictions_with_scores]
            confidence_scores = [score for _, score in predictions_with_scores]
            
            response = PredictionResponse(
                predictions=predictions,
                probabilities=[prob.tolist() for prob in probabilities],
                model_id=self.model_id,
                inference_time=0.0  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ä–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –≤ –±—É–¥—É—â–µ–º
            )
            
            self.logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(predictions)} –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π CNN+MLP")
            return response
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            raise
        finally:
            # üîß –î–û–ë–ê–í–õ–ï–ù–ò–ï: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –º–æ–¥–µ–ª—å –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π —Ä–µ–∂–∏–º (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
            self.model.train()

    def save(self, path: Path) -> None:
        """
        –ü–û–õ–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç AbstractBaseModel –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É
        """
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ checkpoint
            checkpoint = {
                'model_state_dict': self.model.state_dict(),
                'model_config': {
                    'input_size': self.input_size,
                    'hidden_size': self.hidden_size,
                    'architecture': 'CNN+MLP'
                },
                'metadata': self.metadata.model_dump(),
                'is_trained': self._is_trained,
                'model_type': self.model_type.value
            }
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            path.parent.mkdir(parents=True, exist_ok=True)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            torch.save(checkpoint, path)
            
            self.logger.info(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {path}")
            self.logger.info(f"üìã –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: CNN+MLP, input_size: {self.input_size}, hidden_size: {self.hidden_size}")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            raise

    def load(self, path: Path) -> None:
        """
        –ü–û–õ–ù–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø: –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç AbstractBaseModel –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É
        """
        if not path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
        
        try:
            checkpoint = torch.load(path, map_location='cpu', weights_only=False)
            config = checkpoint.get('model_config', {})
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Å –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π
            self.model = EnhancedNumberPredictor(
                input_size=config.get('input_size', self.input_size),
                hidden_size=config.get('hidden_size', self.hidden_size)
            )
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            self._load_model_weights(checkpoint['model_state_dict'])
            
            self.model.to(self.device)
            
            # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è - –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ó–î–ï–°–¨
            if 'metadata' in checkpoint:
                self.metadata = ModelMetadata(**checkpoint['metadata'])
            
            # üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ø—Ä–∞–≤–∏–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –æ–±—É—á–µ–Ω–∏—è
            self._is_trained = checkpoint.get('is_trained', True)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é True –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            
            # üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ø—Ä–∞–≤–∏–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å
            if self._is_trained:
                self.status = ModelStatus.READY
            else:
                self.status = ModelStatus.FAILED
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            self.input_size = config.get('input_size', self.input_size)
            self.hidden_size = config.get('hidden_size', self.hidden_size)
            
            self.logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {path}")
            self.logger.info(f"üìã –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: CNN+MLP, input_size: {self.input_size}, hidden_size: {self.hidden_size}")
            self.logger.info(f"üìä –°—Ç–∞—Ç—É—Å: {'–æ–±—É—á–µ–Ω–∞' if self._is_trained else '–Ω–µ –æ–±—É—á–µ–Ω–∞'}")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            self.status = ModelStatus.FAILED
            raise

    def _load_model_weights(self, state_dict: Dict[str, Any]):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä"""
        try:
            # –ü—Ä—è–º–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –µ—Å–ª–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–∞
            self.model.load_state_dict(state_dict)
            self.logger.info("‚úÖ –ü—Ä—è–º–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤ —É—Å–ø–µ—à–Ω–∞")
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è –ü—Ä—è–º–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
            self.logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            # –î–ª—è –≠–¢–ê–ü–ê 2 –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é
            # –í —Å–ª–µ–¥—É—é—â–∏—Ö —ç—Ç–∞–ø–∞—Ö –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤

    def _prepare_training_data(self, data) -> tuple:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        try:
            if hasattr(data, 'values'):
                features = data.values.astype(np.float32)
            else:
                features = np.array(data, dtype=np.float32)
        
            # –ê–¥–∞–ø—Ç–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ features
            if features.shape[1] != self.input_size:
                self.logger.warning(f"‚ö†Ô∏è –†–∞–∑–º–µ—Ä features {features.shape[1]} != {self.input_size}")
                features = self._adapt_features_size(features)
        
            # –î–ª—è –≠–¢–ê–ü–ê 2: —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö targets –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            # –í —Ä–µ–∞–ª—å–Ω–æ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏ targets –±—É–¥—É—Ç –∏–∑–≤–ª–µ–∫–∞—Ç—å—Å—è –∏–∑ –¥–∞–Ω–Ω—ã—Ö
            batch_size = len(features)
            targets = np.random.randint(0, 26, (batch_size, 4), dtype=np.int64)
        
            return (
                torch.tensor(features, dtype=torch.float32),
                torch.tensor(targets, dtype=torch.long)
            )
        
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return torch.tensor([]), torch.tensor([])

    def _prepare_features_for_prediction(self, data) -> np.ndarray:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ features –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
        try:
            if hasattr(data, 'values'):
                features = data.values.astype(np.float32)
            else:
                features = np.array(data, dtype=np.float32)
            
            # –ê–¥–∞–ø—Ç–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ features
            if features.shape[1] != self.input_size:
                features = self._adapt_features_size(features)
            
            return features
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ features: {e}")
            return np.array([])

    def _adapt_features_size(self, features: np.ndarray) -> np.ndarray:
        """–ê–¥–∞–ø—Ç–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ features –∫ –æ–∂–∏–¥–∞–µ–º–æ–º—É input_size"""
        current_size = features.shape[1]
        
        if current_size < self.input_size:
            # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
            padded = np.zeros((features.shape[0], self.input_size), dtype=np.float32)
            padded[:, :current_size] = features
            self.logger.info(f"üîß Features –¥–æ–ø–æ–ª–Ω–µ–Ω—ã –Ω—É–ª—è–º–∏: {current_size} -> {self.input_size}")
            return padded
        else:
            # –û–±—Ä–µ–∑–∞–µ–º
            trimmed = features[:, :self.input_size]
            self.logger.info(f"üîß Features –æ–±—Ä–µ–∑–∞–Ω—ã: {current_size} -> {self.input_size}")
            return trimmed

    def _generate_enhanced_predictions(self, probabilities: torch.Tensor, top_k: int = 4) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–î–ï–¢–ï–†–ú–ò–ù–ò–†–û–í–ê–ù–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        candidates = []
        
        try:
            # üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤—ã–±–æ—Ä–∞
            for strategy in range(top_k):
                group = []
                confidence = 1.0
                
                for pos in range(4):
                    probs = probabilities[pos]
                    
                    # üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–±–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
                    if strategy == 0:
                        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 0: —Å–∞–º—ã–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–µ —á–∏—Å–ª–∞
                        predicted_num = torch.argmax(probs).item() + 1
                    elif strategy == 1:
                        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –≤—Ç–æ—Ä—ã–µ –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —á–∏—Å–ª–∞
                        top2 = torch.topk(probs, 2)
                        predicted_num = top2.indices[1].item() + 1
                    elif strategy == 2:
                        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: —Ç—Ä–µ—Ç—å–∏ –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —á–∏—Å–ª–∞
                        top3 = torch.topk(probs, 3)
                        predicted_num = top3.indices[2].item() + 1
                    else:
                        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3+: —á–µ—Ç–≤–µ—Ä—Ç—ã–µ –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —á–∏—Å–ª–∞ –∏ —Ç.–¥.
                        topk = torch.topk(probs, strategy + 1)
                        predicted_num = topk.indices[strategy].item() + 1
                    
                    group.append(predicted_num)
                    confidence *= probs[predicted_num - 1].item()
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –≥—Ä—É–ø–ø—ã
                if self._is_valid_group(group):
                    candidates.append((tuple(group), confidence))
            
            # üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –µ—Å–ª–∏ –Ω–µ –Ω–∞–±—Ä–∞–ª–∏ enough –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ
            if len(candidates) < top_k:
                additional_attempts = 0
                while len(candidates) < top_k and additional_attempts < 20:
                    group = []
                    confidence = 1.0
                    
                    for pos in range(4):
                        probs = probabilities[pos]
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
                        predicted_num = (additional_attempts + pos) % 26 + 1
                        group.append(predicted_num)
                        confidence *= probs[predicted_num - 1].item()
                    
                    if self._is_valid_group(group) and tuple(group) not in [c[0] for c in candidates]:
                        candidates.append((tuple(group), confidence))
                    
                    additional_attempts += 1
            
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–ø–æ —É–±—ã–≤–∞–Ω–∏—é)
            candidates.sort(key=lambda x: x[1], reverse=True)
            return candidates[:top_k]
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: {e}")
            # –†–µ–∑–µ—Ä–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
            return self._generate_fallback_predictions()

    def _is_valid_group(self, group: List[int]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –≥—Ä—É–ø–ø—ã —á–∏—Å–µ–ª"""
        if len(group) != 4:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –≤ –ø–∞—Ä–∞—Ö (—Ñ–æ—Ä–º–∞—Ç "12 34 56 78" - –ø–∞—Ä—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —á–∏—Å–µ–ª)
        if group[0] == group[1] or group[2] == group[3]:
            return False
        
        # –í—Å–µ —á–∏—Å–ª–∞ –≤ –¥–æ–ø—É—Å—Ç–∏–º–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ
        if not all(1 <= x <= 26 for x in group):
            return False
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –Ω–µ –≤—Å–µ —á–∏—Å–ª–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
        if len(set(group)) < 2:
            return False
            
        return True

    def _generate_fallback_predictions(self) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–†–µ–∑–µ—Ä–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö"""
        import random
        
        fallback_predictions = []
        
        for i in range(4):
            while True:
                group = tuple(random.sample(range(1, 27), 4))
                if self._is_valid_group(group):
                    fallback_predictions.append((group, 0.001))
                    break
        
        self.logger.warning("üîÑ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
        return fallback_predictions

    def get_model_info(self) -> Dict[str, Any]:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
        return {
            'model_id': self.model_id,
            'architecture': 'EnhancedNumberPredictor (—Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º)',
            'input_size': self.input_size,
            'hidden_size': self.hidden_size,
            'is_trained': self._is_trained,
            'status': self.status.value,
            'feature_specs_count': len(self._feature_specs)
        }

    def validate_features(self, data) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö features"""
        try:
            if hasattr(data, 'shape'):
                if data.shape[1] != self.input_size:
                    self.logger.warning(f"‚ö†Ô∏è –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä features: {data.shape[1]} != {self.input_size}")
                    return False
            return True
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ features: {e}")
            return False
