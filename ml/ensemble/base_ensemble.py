# /opt/model/ml/ensemble/base_ensemble.py
"""
–ß–ò–°–¢–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã - –ë–ï–ó –û–ë–†–ê–¢–ù–û–ô –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò
"""

import numpy as np
from typing import List, Tuple, Dict, Optional
from abc import ABC, abstractmethod
import logging
from pathlib import Path

from ml.core.base_model import AbstractBaseModel
from ml.core.types import (
    ModelType, ModelStatus, TrainingConfig, 
    ModelMetadata, TrainingResult, PredictionResponse,
    DataBatch, FeatureSpec
)


class AbstractEnsemblePredictor(AbstractBaseModel, ABC):
    """
    –ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å - –ß–ò–°–¢–´–ô –ò–ù–¢–ï–†–§–ï–ô–°
    """
    
    def __init__(self, model_id: str, model_type: ModelType = ModelType.CLASSIFICATION):
        super().__init__(model_id, model_type)
        self.component_predictors: Dict[str, AbstractBaseModel] = {}
        self.weights: Dict[str, float] = {}
        self._prediction_lock = False
        
        self.logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å: {model_id}")

    @abstractmethod
    def combine_predictions(self, component_results: Dict[str, PredictionResponse]) -> PredictionResponse:
        """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        pass

    def add_predictor(self, predictor_id: str, predictor: AbstractBaseModel, weight: float = 1.0) -> None:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—è –≤ –∞–Ω—Å–∞–º–±–ª—å"""
        self.component_predictors[predictor_id] = predictor
        self.weights[predictor_id] = weight
        self.logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å {predictor_id} —Å –≤–µ—Å–æ–º {weight}")

    def set_predictor_weight(self, predictor_id: str, weight: float) -> None:
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–µ—Å–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—è"""
        if predictor_id in self.component_predictors:
            self.weights[predictor_id] = weight
            self.logger.info(f"‚öñÔ∏è –í–µ—Å {predictor_id} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {weight}")
        else:
            raise ValueError(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å {predictor_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")

    def train(self, data: DataBatch, config: TrainingConfig) -> TrainingResult:
        """–û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∞–Ω—Å–∞–º–±–ª—è"""
        self.logger.info("üîÑ –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã")
        
        training_results = {}
        
        for predictor_id, predictor in self.component_predictors.items():
            try:
                if not predictor.is_trained:
                    result = predictor.train(data, config)
                    training_results[predictor_id] = result
                    self.logger.info(f"‚úÖ {predictor_id} –æ–±—É—á–µ–Ω")
                else:
                    self.logger.info(f"‚è≠Ô∏è {predictor_id} —É–∂–µ –æ–±—É—á–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è {predictor_id}: {e}")
                raise

        self._is_trained = True
        self.status = ModelStatus.TRAINED
        
        return TrainingResult(
            model_id=self.model_id,
            status=self.status,
            metrics={'component_results': training_results}
        )

    def predict(self, data: DataBatch) -> PredictionResponse:
        """–ê–Ω—Å–∞–º–±–ª–µ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ - –û–°–ù–û–í–ù–û–ô –ú–ï–¢–û–î –ù–û–í–û–ô –ê–†–•–ò–¢–ï–ö–¢–£–†–´"""
        if self._prediction_lock:
            self.logger.warning("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Ä–µ–∫—É—Ä—Å–∏—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
            return PredictionResponse(
                predictions=[],
                model_id=self.model_id,
                inference_time=0.0
            )
        
        self._prediction_lock = True
        
        try:
            if not self._is_trained:
                raise ValueError("–ê–Ω—Å–∞–º–±–ª—å –Ω–µ –æ–±—É—á–µ–Ω")
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            component_results = {}
            for predictor_id, predictor in self.component_predictors.items():
                if predictor.is_trained:
                    try:
                        response = predictor.predict(data)
                        component_results[predictor_id] = response
                    except Exception as e:
                        self.logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è {predictor_id}: {e}")
                        continue
            
            # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            ensemble_response = self.combine_predictions(component_results)
            return ensemble_response
            
        finally:
            self._prediction_lock = False

    def save(self, path: Path) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –∏ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        ensemble_config = {
            'model_id': self.model_id,
            'model_type': self.model_type.value,
            'weights': self.weights,
            # üîß –£–ë–†–ê–ù–´ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å datetime
            'components': list(self.component_predictors.keys())
        }
        
        import json
        config_path = path / f"{self.model_id}_ensemble_config.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(ensemble_config, f, indent=2, ensure_ascii=False)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        for predictor_id, predictor in self.component_predictors.items():
            predictor_path = path / predictor_id
            predictor_path.mkdir(exist_ok=True)
            predictor.save(predictor_path)
        
        self.logger.info(f"üíæ –ê–Ω—Å–∞–º–±–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {path}")
          
    def load(self, path: Path) -> None:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω—Å–∞–º–±–ª—è –∏ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        config_path = path / f"{self.model_id}_ensemble_config.json"
        
        if not config_path.exists():
            raise FileNotFoundError(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–Ω—Å–∞–º–±–ª—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {config_path}")
        
        import json
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–µ—Å–∞
        self.weights = config.get('weights', {})
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã)
        for predictor_id in config.get('components', []):
            predictor_path = path / predictor_id
            if predictor_id in self.component_predictors and predictor_path.exists():
                self.component_predictors[predictor_id].load(predictor_path)
        
        self._is_trained = True
        self.status = ModelStatus.READY
        self.logger.info(f"üì• –ê–Ω—Å–∞–º–±–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω: {path}")


class WeightedEnsemblePredictor(AbstractEnsemblePredictor):
    """
    –í–∑–≤–µ—à–µ–Ω–Ω—ã–π –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–π –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å - –ß–ò–°–¢–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø
    """
    
    def __init__(self, model_id: str = "weighted_ensemble"):
        super().__init__(model_id)
        self.logger.info("üéØ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω WeightedEnsemblePredictor")

    def combine_predictions(self, component_results: Dict[str, PredictionResponse]) -> PredictionResponse:
        """–í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π - –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê"""
        if not component_results:
            return PredictionResponse(
                predictions=[],
                model_id=self.model_id,
                inference_time=0.0
            )
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –≤–µ—Å–∞–º–∏
        all_weighted_predictions = []
        
        for predictor_id, response in component_results.items():
            weight = self.weights.get(predictor_id, 1.0)
            
            for i, prediction in enumerate(response.predictions):
                # –ë–∞–∑–æ–≤—ã–π score
                base_score = 1.0
                if response.probabilities and i < len(response.probabilities):
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–∞–∫ confidence
                    base_score = float(np.max(response.probabilities[i]))
                
                weighted_score = base_score * weight
                all_weighted_predictions.append((prediction, weighted_score))
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º
        aggregated_scores = {}
        for prediction, score in all_weighted_predictions:
            prediction_key = tuple(prediction) if isinstance(prediction, (list, tuple)) else prediction
            
            if prediction_key in aggregated_scores:
                aggregated_scores[prediction_key] += score
            else:
                aggregated_scores[prediction_key] = score
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é score
        sorted_predictions = sorted(
            [(pred, score) for pred, score in aggregated_scores.items()],
            key=lambda x: x[1],
            reverse=True
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
        final_predictions = [pred for pred, score in sorted_predictions]
        
        self.logger.info(f"üîÄ –°–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–æ {len(final_predictions)} –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –æ—Ç {len(component_results)} –º–æ–¥–µ–ª–µ–π")
        
        return PredictionResponse(
            predictions=final_predictions,
            model_id=self.model_id,
            inference_time=0.0
        )

