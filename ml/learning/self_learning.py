# [file name]: ml/learning/self_learning.py
"""
–°–∏—Å—Ç–µ–º–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—à–∏–±–∫–∞—Ö - –†–ï–§–ê–ö–¢–û–†–ò–ù–ì –î–õ–Ø –ù–û–í–û–ô –°–¢–†–£–ö–¢–£–†–´
"""

import json
import os
from typing import List, Tuple, Dict, Any
from datetime import datetime

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
from ml.core.data_processor import DataProcessor
from ml.features.extractor import BaseFeatureExtractor
from config.paths import DATA_DIR

class SelfLearningSystem:
    def __init__(self, results_file: str = None):
        if results_file is None:
            results_file = os.path.join(DATA_DIR, "analytics", "learning_results.json")
        self.results_file = results_file
        self.learning_data = self._load_learning_data()
   
    def _load_learning_data(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        if os.path.exists(self.results_file):
            try:
                with open(self.results_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                print(f"üîç –ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ —Ç–∏–ø–∞: {type(data)}")
                
                # üîß –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                if isinstance(data, list):
                    print("‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω –º–∞—Å—Å–∏–≤ –¥–∞–Ω–Ω—ã—Ö, –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É...")
                    
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                    correct_structure = {
                        'predictions_accuracy': [],
                        'model_performance': {},
                        'learning_patterns': {},
                        'error_patterns': [],
                        'last_analysis': None
                    }
                    
                    for i, item in enumerate(data):
                        if isinstance(item, dict):
                            # –ï—Å–ª–∏ —ç—Ç–æ –æ—Å–Ω–æ–≤–Ω–æ–π —Å–ª–æ–≤–∞—Ä—å —Å–æ –≤—Å–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π (–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤–ª–æ–∂–µ–Ω–Ω—ã–π)
                            if 'predictions_accuracy' in item and isinstance(item['predictions_accuracy'], list):
                                print(f"üì¶ –ù–∞–π–¥–µ–Ω –æ—Å–Ω–æ–≤–Ω–æ–π —Å–ª–æ–≤–∞—Ä—å —Å {len(item['predictions_accuracy'])} –∑–∞–ø–∏—Å—è–º–∏")
                                # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
                                correct_structure['predictions_accuracy'].extend(item['predictions_accuracy'])
                                
                                # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –æ—à–∏–±–∫–∏
                                if 'error_patterns' in item and isinstance(item['error_patterns'], list):
                                    correct_structure['error_patterns'] = item['error_patterns']
                                
                                # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è
                                for key in ['model_performance', 'learning_patterns', 'last_analysis']:
                                    if key in item:
                                        correct_structure[key] = item[key]
                            
                            # –ï—Å–ª–∏ —ç—Ç–æ –æ—Ç–¥–µ–ª—å–Ω–∞—è –∑–∞–ø–∏—Å—å –∞–Ω–∞–ª–∏–∑–∞
                            elif 'timestamp' in item and 'actual_group' in item:
                                print(f"üìä –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –∞–Ω–∞–ª–∏–∑–∞: {item.get('actual_group', 'N/A')}")
                                correct_structure['predictions_accuracy'].append(item)
                            
                            # –ï—Å–ª–∏ —ç—Ç–æ –∑–∞–ø–∏—Å—å —Ç–∏—Ä–∞–∂–∞
                            elif 'draw' in item and 'combination' in item:
                                print(f"üéØ –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å —Ç–∏—Ä–∞–∂–∞: {item.get('draw', 'N/A')}")
                                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
                                analysis_entry = {
                                    'timestamp': item.get('timestamp'),
                                    'actual_group': item.get('combination', ''),
                                    'draw': item.get('draw', ''),
                                    'service_type': item.get('service_type', 'auto_learning'),
                                    'learning_success': item.get('learning_success', True),
                                    'new_predictions_count': item.get('new_predictions_count', 0)
                                }
                                
                                # –í—ã—á–∏—Å–ª—è–µ–º accuracy_score –∏–∑ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                                if 'comparison' in item and 'matches_found' in item['comparison']:
                                    matches_count = item['comparison']['matches_found']
                                    analysis_entry['matches_count'] = matches_count
                                    analysis_entry['accuracy_score'] = matches_count / 4.0
                                
                                correct_structure['predictions_accuracy'].append(analysis_entry)
                    
                    print(f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {len(correct_structure['predictions_accuracy'])} –∑–∞–ø–∏—Å–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏")
                    print(f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {len(correct_structure['error_patterns'])} –∑–∞–ø–∏—Å–µ–π –æ—à–∏–±–æ–∫")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                    self.learning_data = correct_structure
                    self._save_learning_data()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
                    print("üíæ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
                    
                    return correct_structure
                    
                elif isinstance(data, dict):
                    print("‚úÖ –î–∞–Ω–Ω—ã–µ —É–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ")
                    return data
                else:
                    print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö: {type(data)}")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è: {e}")
                import traceback
                traceback.print_exc()
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return {
            'predictions_accuracy': [],
            'model_performance': {},
            'learning_patterns': {},
            'error_patterns': [],
            'last_analysis': None
        }

    def get_performance_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            if isinstance(self.learning_data, dict):
                accuracy_data = self.learning_data.get('predictions_accuracy', [])
                print(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏: {len(accuracy_data)}")
            else:
                accuracy_data = []
            
            if not accuracy_data:
                return {
                    'message': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞',
                    'total_predictions_analyzed': 0,
                    'recent_accuracy_avg': 0,
                    'best_accuracy': 0,
                    'worst_accuracy': 0,
                    'stability_score': 0,
                    'trend': 'unknown',
                    'recommendations': ['üìä –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...']
                }
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–∏ —Å accuracy_score
            valid_data = [item for item in accuracy_data if isinstance(item, dict) and 'accuracy_score' in item]
            print(f"‚úÖ –í–∞–ª–∏–¥–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π —Å accuracy_score: {len(valid_data)}")
            
            if not valid_data:
                return {
                    'message': '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞',
                    'total_predictions_analyzed': 0,
                    'recent_accuracy_avg': 0,
                    'best_accuracy': 0,
                    'worst_accuracy': 0,
                    'stability_score': 0,
                    'trend': 'unknown',
                    'recommendations': ['üîß –¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–∞–Ω–Ω—ã—Ö']
                }
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö (20 –∑–∞–ø–∏—Å–µ–π –∏–ª–∏ –≤—Å–µ –µ—Å–ª–∏ –º–µ–Ω—å—à–µ)
            recent_data = valid_data[-20:]
            recent_accuracy = [a.get('accuracy_score', 0) for a in recent_data]
            
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            accuracy_values = [a.get('accuracy_score', 0) for a in valid_data]
            
            # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞
            trend = "stable"
            if len(recent_accuracy) >= 5:
                first_half = recent_accuracy[:len(recent_accuracy)//2]
                second_half = recent_accuracy[len(recent_accuracy)//2:]
                avg_first = sum(first_half) / len(first_half)
                avg_second = sum(second_half) / len(second_half)
                
                if avg_second > avg_first + 0.15:
                    trend = "improving"
                elif avg_second < avg_first - 0.15:
                    trend = "declining"
            
            # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)
            if len(recent_accuracy) > 1:
                mean_accuracy = sum(recent_accuracy) / len(recent_accuracy)
                variance = sum((x - mean_accuracy) ** 2 for x in recent_accuracy) / len(recent_accuracy)
                stability_score = max(0, 1 - (variance ** 0.5))  # 1 = –∏–¥–µ–∞–ª—å–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
            else:
                stability_score = 1.0
            
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏
            perfect_matches = len([a for a in accuracy_values if a == 1.0])
            good_matches = len([a for a in accuracy_values if a >= 0.5])
            poor_matches = len([a for a in accuracy_values if a < 0.25])
            
            return {
                'total_predictions_analyzed': len(valid_data),
                'recent_accuracy_avg': sum(recent_accuracy) / len(recent_accuracy),
                'best_accuracy': max(recent_accuracy) if recent_accuracy else 0,
                'worst_accuracy': min(recent_accuracy) if recent_accuracy else 0,
                'stability_score': stability_score,
                'trend': trend,
                'distribution': {
                    'perfect_matches': perfect_matches,
                    'good_matches': good_matches,
                    'poor_matches': poor_matches,
                    'total_matches': len(valid_data)
                },
                'recommendations': self.get_learning_recommendations(),
                'debug_info': {
                    'total_entries': len(accuracy_data),
                    'valid_entries': len(valid_data),
                    'recent_analyzed': len(recent_data),
                    'data_format': 'corrected'
                }
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ get_performance_stats: {e}")
            import traceback
            traceback.print_exc()
            return {
                'message': f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}',
                'total_predictions_analyzed': 0,
                'recent_accuracy_avg': 0,
                'best_accuracy': 0,
                'worst_accuracy': 0,
                'stability_score': 0,
                'trend': 'error',
                'recommendations': ['‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö']
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ get_performance_stats: {e}")
            import traceback
            traceback.print_exc()
            return {'message': f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}'}

    def get_learning_recommendations(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è"""
        recommendations = []
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            if isinstance(self.learning_data, dict):
                accuracy_data = self.learning_data.get('predictions_accuracy', [])
                error_patterns = self.learning_data.get('error_patterns', [])
            else:
                accuracy_data = []
                error_patterns = []
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            valid_data = [item for item in accuracy_data if isinstance(item, dict) and 'accuracy_score' in item]
            
            print(f"üîç –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑: {len(valid_data)} –∑–∞–ø–∏—Å–µ–π, {len(error_patterns)} –æ—à–∏–±–æ–∫")
            
            # 1. –ê–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            if valid_data:
                recent_accuracy = [a['accuracy_score'] for a in valid_data[-10:]]
                all_accuracy = [a['accuracy_score'] for a in valid_data]
                
                avg_recent = sum(recent_accuracy) / len(recent_accuracy)
                avg_all = sum(all_accuracy) / len(all_accuracy)
                
                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏
                if avg_recent < 0.2:
                    recommendations.append("üö® **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å** - —Ç—Ä–µ–±—É–µ—Ç—Å—è —Å—Ä–æ—á–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ")
                elif avg_recent < 0.3:
                    recommendations.append("‚ö†Ô∏è **–ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å** - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ–ª–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏")
                elif avg_recent < 0.5:
                    recommendations.append("üìâ **–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å** - –¥–æ–±–∞–≤—å—Ç–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                elif avg_recent > 0.7:
                    recommendations.append("‚úÖ **–í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å** - —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ")
                elif avg_recent > 0.8:
                    recommendations.append("üèÜ **–û—Ç–ª–∏—á–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å** - –º–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã–¥–∞—é—â–∏–µ—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
                
                # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞
                if len(recent_accuracy) >= 5:
                    first_part = recent_accuracy[:len(recent_accuracy)//2]
                    second_part = recent_accuracy[len(recent_accuracy)//2:]
                    avg_first = sum(first_part) / len(first_part)
                    avg_second = sum(second_part) / len(second_part)
                    
                    improvement = avg_second - avg_first
                    if improvement > 0.1:
                        recommendations.append("üìà **–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞** - —Ç–æ—á–Ω–æ—Å—Ç—å —É–ª—É—á—à–∞–µ—Ç—Å—è, –ø—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —Ç–µ–∫—É—â—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é")
                    elif improvement < -0.1:
                        recommendations.append("üìâ **–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞** - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
                
                # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
                accuracy_std = (sum((x - avg_recent) ** 2 for x in recent_accuracy) / len(recent_accuracy)) ** 0.5
                if accuracy_std > 0.3:
                    recommendations.append("üé≠ **–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã** - –º–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏")
                elif accuracy_std < 0.1:
                    recommendations.append("‚öñÔ∏è **–°—Ç–∞–±–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞** - –º–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç consistent —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            
            # 2. –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ—à–∏–±–æ–∫
            if error_patterns:
                recent_errors = error_patterns[-20:]
                
                # –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç—ã—Ö –æ—à–∏–±–æ–∫
                missed_numbers = {}
                false_numbers = {}
                
                for error in recent_errors:
                    for num in error.get('missed_numbers', []):
                        missed_numbers[num] = missed_numbers.get(num, 0) + 1
                    for num in error.get('false_numbers', []):
                        false_numbers[num] = false_numbers.get(num, 0) + 1
                
                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —á–∏—Å–ª–∞–º
                if missed_numbers:
                    most_missed = max(missed_numbers.items(), key=lambda x: x[1])
                    if most_missed[1] >= 3:
                        recommendations.append(f"üîç **–ß–∏—Å–ª–æ {most_missed[0]} —á–∞—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è** - —É–≤–µ–ª–∏—á—å—Ç–µ –µ–≥–æ –≤–µ—Å –≤ features")
                
                if false_numbers:
                    most_false = max(false_numbers.items(), key=lambda x: x[1])
                    if most_false[1] >= 3:
                        recommendations.append(f"üéØ **–ß–∏—Å–ª–æ {most_false[0]} —á–∞—Å—Ç–æ –ª–æ–∂–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è** - —É–º–µ–Ω—å—à–∏—Ç–µ –µ–≥–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç")
                
                # –ß–∞—Å—Ç–æ—Ç–∞ —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –æ—à–∏–±–æ–∫
                severe_errors = [e for e in recent_errors if e.get('accuracy', 1) < 0.25]
                if len(severe_errors) > len(recent_errors) * 0.6:
                    recommendations.append("üîÑ **–ú–Ω–æ–≥–æ —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –æ—à–∏–±–æ–∫** - –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–∏—Ç–µ feature engineering")
            
            # 3. –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
            if valid_data:
                accuracy_values = [a['accuracy_score'] for a in valid_data]
                perfect_count = len([a for a in accuracy_values if a == 1.0])
                good_count = len([a for a in accuracy_values if a >= 0.5])
                poor_count = len([a for a in accuracy_values if a < 0.25])
                
                total_count = len(valid_data)
                
                if perfect_count > 0:
                    perfect_percent = (perfect_count / total_count) * 100
                    recommendations.append(f"‚≠ê **{perfect_count} –∏–¥–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π** ({perfect_percent:.1f}%)")
                
                if poor_count > total_count * 0.4:
                    recommendations.append("üîß **–ú–Ω–æ–≥–æ –ø—Ä–æ–º–∞—Ö–æ–≤** - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ preprocessing –¥–∞–Ω–Ω—ã—Ö")
                
                success_rate = (good_count / total_count) * 100
                if success_rate > 60:
                    recommendations.append("üí™ **–•–æ—Ä–æ—à–∏–π success rate** - –º–æ–¥–µ–ª—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞")
                elif success_rate < 30:
                    recommendations.append("üéØ **–ù–∏–∑–∫–∏–π success rate** - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Å–º–µ–Ω—É –∞–ª–≥–æ—Ä–∏—Ç–º–∞")
            
            # 4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–±—ä–µ–º—É –∏ –∫–∞—á–µ—Å—Ç–≤—É –¥–∞–Ω–Ω—ã—Ö
            total_entries = len(valid_data)
            if total_entries < 10:
                recommendations.append("üìà **–ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö** - –ø—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —Å–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
            elif total_entries < 50:
                recommendations.append("üìä **–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö** - –º–æ–∂–Ω–æ –ø—Ä–æ–≤–æ–¥–∏—Ç—å –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
            elif total_entries > 100:
                recommendations.append("üíæ **–ë–æ–ª—å—à–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö** - –Ω–∞–¥–µ–∂–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã–≤–æ–¥—ã")
            
            # 5. –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –µ—Å–ª–∏ –Ω–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö
            if not recommendations:
                if valid_data:
                    recent_avg = sum([a['accuracy_score'] for a in valid_data[-5:]]) / min(5, len(valid_data))
                    if recent_avg < 0.4:
                        recommendations.append("üîÑ **–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è** - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ fine-tuning –º–æ–¥–µ–ª–∏")
                    else:
                        recommendations.append("‚ö° **–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –æ–±—É—á–µ–Ω–∏–µ** - —Ç–µ–∫—É—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞")
                else:
                    recommendations.append("üìù **–ù–∞—á–∞–ª—å–Ω–∞—è —Ñ–∞–∑–∞** - —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ—è–≤—è—Ç—Å—è –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–∏—Ä–∞–∂–µ–π")
            
            # 6. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —á–∞—Å—Ç–æ—Ç–µ –æ–±—É—á–µ–Ω–∏—è
            if len(valid_data) > 20:
                recent_timestamps = [a.get('timestamp') for a in valid_data[-5:] if a.get('timestamp')]
                if recent_timestamps:
                    try:
                        from datetime import datetime
                        timestamps = [datetime.fromisoformat(ts) for ts in recent_timestamps if ts]
                        if timestamps:
                            time_diffs = [(timestamps[i] - timestamps[i-1]).total_seconds() for i in range(1, len(timestamps))]
                            if time_diffs:
                                avg_interval = sum(time_diffs) / len(time_diffs)
                                if avg_interval > 86400:  # –±–æ–ª–µ–µ —Å—É—Ç–æ–∫
                                    recommendations.append("‚è∞ **–†–µ–¥–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ** - —É–≤–µ–ª–∏—á—å—Ç–µ —á–∞—Å—Ç–æ—Ç—É –¥–æ–æ–±—É—á–µ–Ω–∏—è")
                                elif avg_interval < 3600:  # –º–µ–Ω–µ–µ —á–∞—Å–∞
                                    recommendations.append("‚ö° **–ß–∞—Å—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ** - —Ö–æ—Ä–æ—à–∏–π —Ç–µ–º–ø –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
                    except:
                        pass
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ get_learning_recommendations: {e}")
            recommendations = ["‚ö†Ô∏è **–í—Ä–µ–º–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞** - —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±—É–¥—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã –ø–æ—Å–ª–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–∏—Ä–∞–∂–∞"]
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –≤—ã–±–∏—Ä–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–µ
        if len(recommendations) > 6:
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ -> —Ç–æ—á–Ω–æ—Å—Ç—å -> –æ—à–∏–±–∫–∏ -> –æ–±—â–∏–µ
            critical = [r for r in recommendations if 'üö®' in r or '‚ö†Ô∏è' in r]
            accuracy = [r for r in recommendations if 'üìà' in r or 'üìâ' in r or '‚úÖ' in r]
            errors = [r for r in recommendations if 'üîç' in r or 'üéØ' in r]
            general = [r for r in recommendations if r not in critical + accuracy + errors]
            
            recommendations = critical + accuracy[:2] + errors[:2] + general[:1]
        
        return recommendations[:6]  # –ú–∞–∫—Å–∏–º—É–º 6 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
       
    def analyze_prediction_accuracy(self, actual_group: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        try:
            from ml.utils.data_utils import compare_groups, load_predictions
            
            actual_numbers = [int(x) for x in actual_group.strip().split()]
            actual_tuple = tuple(actual_numbers)
            
            previous_predictions = load_predictions()
            if not previous_predictions:
                return None
            
            best_match = None
            best_score = 0
            best_prediction = None
            
            # –ò—â–µ–º –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å—Ä–µ–¥–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            for pred_group, score in previous_predictions:
                comparison = compare_groups(pred_group, actual_tuple)
                total_matches = comparison['total_matches']
                
                if total_matches > best_score:
                    best_score = total_matches
                    best_match = comparison
                    best_prediction = pred_group
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            analysis_result = {
                'timestamp': datetime.now().isoformat(),
                'actual_group': actual_group,
                'best_prediction': best_prediction,
                'matches_count': best_score,
                'comparison_details': best_match,
                'accuracy_score': best_score / 4.0  # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
            }
            
            # ‚ö° –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–∞ –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º
            if 'predictions_accuracy' not in self.learning_data:
                self.learning_data['predictions_accuracy'] = []
                
            self.learning_data['predictions_accuracy'].append(analysis_result)
            self._save_learning_data()
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫
            self._analyze_error_patterns(analysis_result)
            
            return analysis_result
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏: {e}")
            return None
    
    def _analyze_error_patterns(self, analysis_result: Dict):
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ—à–∏–±–æ–∫ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        accuracy = analysis_result['accuracy_score']
        
        if accuracy < 0.5:  # –ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
            actual_group = analysis_result['actual_group']
            predicted_group = analysis_result['best_prediction']
            
            if predicted_group:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º, –∫–∞–∫–∏–µ —á–∏—Å–ª–∞ –±—ã–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω—ã
                actual_numbers = [int(x) for x in actual_group.split()]
                predicted_numbers = list(predicted_group)
                
                missed_numbers = set(actual_numbers) - set(predicted_numbers)
                false_numbers = set(predicted_numbers) - set(actual_numbers)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫
                if 'error_patterns' not in self.learning_data:
                    self.learning_data['error_patterns'] = []
                
                error_pattern = {
                    'timestamp': analysis_result['timestamp'],
                    'missed_numbers': list(missed_numbers),
                    'false_numbers': list(false_numbers),
                    'accuracy': accuracy
                }
                
                self.learning_data['error_patterns'].append(error_pattern)

    def adjust_ensemble_weights(self, ensemble_predictor) -> bool:
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –≤–µ—Å–æ–≤ –∞–Ω—Å–∞–º–±–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            accuracy_data = self.learning_data.get('predictions_accuracy', [])
            if len(accuracy_data) < 5:  # –ù—É–∂–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
                return False
            
            # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
            recent_accuracy = accuracy_data[-10:]
            accuracy_scores = [a['accuracy_score'] for a in recent_accuracy if 'accuracy_score' in a]
            
            if not accuracy_scores:
                return False
                
            avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)
            
            if avg_accuracy < 0.4:
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
                if hasattr(ensemble_predictor, 'weights') and 'neural' in ensemble_predictor.weights:
                    ensemble_predictor.weights['neural'] = min(0.5, ensemble_predictor.weights['neural'] + 0.1)
                    if 'frequency' in ensemble_predictor.weights:
                        ensemble_predictor.weights['frequency'] = max(0.2, ensemble_predictor.weights['frequency'] - 0.05)
                    print("üîß –°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤–µ—Å–∞ –∞–Ω—Å–∞–º–±–ª—è –≤ –ø–æ–ª—å–∑—É –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
                    return True
                
            return False
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –≤–µ—Å–æ–≤: {e}")
            return False
    
    def _save_learning_data(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è"""
        try:
            os.makedirs(os.path.dirname(self.results_file), exist_ok=True)
            self.learning_data['last_analysis'] = datetime.now().isoformat()
            
            with open(self.results_file, 'w', encoding='utf-8') as f:
                json.dump(self.learning_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è: {e}")

    def reset_learning_data(self):
        """–°–±—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–∏—è"""
        self.learning_data = {
            'predictions_accuracy': [],
            'model_performance': {},
            'learning_patterns': {},
            'error_patterns': [],
            'last_analysis': None
        }
        self._save_learning_data()
        print("‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–∏—è —Å–±—Ä–æ—à–µ–Ω—ã")

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
def create_self_learning_system():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏—è (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
    return SelfLearningSystem()
