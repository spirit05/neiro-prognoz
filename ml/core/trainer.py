# [file name]: ml/core/trainer.py
"""
–û–±—É—á–µ–Ω–∏–µ –£–°–ò–õ–ï–ù–ù–û–ô –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ - –£–ü–†–û–©–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø –∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from typing import List, Tuple
import os
import time
import gc
from config import paths, logging_config, constants
from ml.utils.data_utils import save_predictions

logger = logging_config.get_ml_system_logger()

class EnhancedTrainer:
    def __init__(self, model_path: str = None):
        self.model_path = model_path or paths.MODEL_FILE
        self.device = torch.device('cpu')
        self.model = None
        self.criterion = nn.CrossEntropyLoss()
        self.progress_callback = None
    
    def set_progress_callback(self, callback):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ callback –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        self.progress_callback = callback
    
    def _report_progress(self, message):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ"""
        logger.info(message)
        if self.progress_callback:
            self.progress_callback(message)
   
    def train(self, groups: List[str], epochs=None, batch_size=None, learning_rate=None, is_finetune=False) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ü–†–û–°–¢–´–ú–ò –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ"""
        from config.constants import MAIN_TRAINING_EPOCHS, MAIN_BATCH_SIZE, MAIN_LEARNING_RATE, HIDDEN_SIZE
        
        # üîß –£–ü–†–û–©–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ
        if epochs is None:
            epochs = 15  # –ú–µ–Ω—å—à–µ —ç–ø–æ—Ö –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        if batch_size is None:
            batch_size = 32  # –ú–µ–Ω—å—à–µ batch_size
        if learning_rate is None:
            learning_rate = 0.001  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π learning rate
            
        total_start_time = time.time() 

        self._report_progress(f"üöÄ –û–ë–£–ß–ï–ù–ò–ï: {len(groups)} –≥—Ä—É–ø–ø, {epochs} —ç–ø–æ—Ö")

        # –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        stage1_start = time.time()
        self._report_progress("üìä –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

        from ml.core.data_processor import DataProcessor
        processor = DataProcessor(history_size=25)
        features, targets = processor.prepare_training_data(groups)

        stage1_time = time.time() - stage1_start
        self._report_progress(f"‚úÖ –≠—Ç–∞–ø 1 –∑–∞–≤–µ—Ä—à–µ–Ω: {stage1_time:.1f} —Å–µ–∫")

        if len(features) == 0:
            self._report_progress("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return []

        if len(features) < 20:
            self._report_progress(f"‚ö†Ô∏è –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö: {len(features)} –ø—Ä–∏–º–µ—Ä–æ–≤")
            return []

        self._report_progress(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(features)} –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")

        # –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        stage2_start = time.time()
        self._report_progress("üîß –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

        if self.model is None:
            from ml.core.model import EnhancedNumberPredictor
            # üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º input_size –∏–∑ –¥–∞–Ω–Ω—ã—Ö
            input_size = features.shape[1]
            self.model = EnhancedNumberPredictor(input_size=input_size, hidden_size=128)
            self._report_progress(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å: input_size={input_size}")
        else:
            self._report_progress("üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å")

        stage2_time = time.time() - stage2_start
        self._report_progress(f"‚úÖ –≠—Ç–∞–ø 2 –∑–∞–≤–µ—Ä—à–µ–Ω: {stage2_time:.1f} —Å–µ–∫")

        # –≠—Ç–∞–ø 3: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
        stage3_start = time.time()
        self._report_progress("‚öôÔ∏è –≠—Ç–∞–ø 3: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞...")

        # üîß –£–ü–†–û–©–ï–ù–ò–ï: –ü—Ä–æ—Å—Ç–æ–π Adam –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ
        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)
        # üîß –£–ë–ò–†–ê–ï–ú —Å–ª–æ–∂–Ω—ã–π scheduler –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏

        stage3_time = time.time() - stage3_start
        self._report_progress(f"‚úÖ –≠—Ç–∞–ø 3 –∑–∞–≤–µ—Ä—à–µ–Ω: {stage3_time:.1f} —Å–µ–∫")

        features_tensor = torch.tensor(features, dtype=torch.float32)
        targets_tensor = torch.tensor(targets, dtype=torch.long) - 1  # –î–ª—è CrossEntropy

        # –≠—Ç–∞–ø 4: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        stage4_start = time.time()
        self._report_progress("üß† –≠—Ç–∞–ø 4: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

        self.model.train()
        best_loss = float('inf')

        for epoch in range(epochs):
            epoch_start_time = time.time()
            # üîß –£–ü–†–û–©–ï–ù–ò–ï: –ü—Ä–æ—Å—Ç–æ–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –±–µ–∑ shuffling –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            total_loss = 0
            num_batches = 0

            for i in range(0, len(features), batch_size):
                batch_start = i
                batch_end = min(i + batch_size, len(features))
                if batch_end - batch_start < 2:
                    continue

                batch_features = features_tensor[batch_start:batch_end]
                batch_targets = targets_tensor[batch_start:batch_end]

                self.optimizer.zero_grad()
                outputs = self.model(batch_features)

                # üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ—Å—Ç–æ–π —Ä–∞—Å—á–µ—Ç loss
                loss = 0
                for pos in range(4):
                    loss += self.criterion(outputs[:, pos, :], batch_targets[:, pos])
                loss = loss / 4

                loss.backward()
                self.optimizer.step()

                total_loss += loss.item()
                num_batches += 1

            epoch_time = time.time() - epoch_start_time

            if num_batches > 0:
                avg_loss = total_loss / num_batches
                self._report_progress(f"üìà –≠–ø–æ—Ö–∞ {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, –í—Ä–µ–º—è: {epoch_time:.1f} —Å–µ–∫")

                if avg_loss < best_loss:
                    best_loss = avg_loss
                    self._save_model()
                    self._report_progress(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å (loss: {avg_loss:.4f})")

        stage4_time = time.time() - stage4_start
        self._report_progress(f"‚úÖ –≠—Ç–∞–ø 4 –∑–∞–≤–µ—Ä—à–µ–Ω: {stage4_time:.1f} —Å–µ–∫")
        self._report_progress(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –õ—É—á—à–∏–π loss: {best_loss:.4f}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
        self._save_model()

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
        predictions = self._generate_predictions_after_training(groups)
        
        total_time = time.time() - total_start_time
        self._report_progress(f"üéâ –í–°–ï –≠–¢–ê–ü–´ –ó–ê–í–ï–†–®–ï–ù–´! –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.1f} —Å–µ–∫")

        return predictions
    
    def _generate_predictions_after_training(self, groups: List[str]) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è - –£–ü–†–û–©–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        predictions = []
        try:
            if self.model is not None:
                self.model.eval()
                from ml.core.data_processor import DataProcessor
                processor = DataProcessor(history_size=25)
                recent_groups = groups[-25:] if len(groups) >= 25 else groups

                context_features = processor.create_prediction_features(recent_groups)

                if context_features is not None and len(context_features) > 0:
                    with torch.no_grad():
                        features_tensor = torch.tensor(context_features, dtype=torch.float32)
                        outputs = self.model(features_tensor)
                        
                        # üîß –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ—Å—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
                        for i in range(min(5, len(outputs))):
                            predicted_numbers = []
                            confidence = 1.0
                            for pos in range(4):
                                probs = torch.softmax(outputs[i, pos, :], dim=0)
                                predicted_num = torch.argmax(probs).item() + 1
                                predicted_numbers.append(predicted_num)
                                confidence *= probs[predicted_num - 1].item()
                            
                            # üîß –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —á–∏—Å–ª–∞ —Ä–∞–∑–Ω—ã–µ
                            if len(set(predicted_numbers)) >= 3:  # –•–æ—Ç—è –±—ã 3 —Ä–∞–∑–Ω—ã—Ö —á–∏—Å–ª–∞
                                predictions.append((tuple(predicted_numbers), confidence))
                        
                        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ö–æ—Ä–æ—à–∏–µ –ø—Ä–æ–≥–Ω–æ–∑—ã, —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ
                        if not predictions:
                            self._report_progress("‚ö†Ô∏è  –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã...")
                            predictions = self._create_basic_predictions()
                            
        except Exception as e:
            self._report_progress(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: {e}")
            predictions = self._create_basic_predictions()

        self._report_progress(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(predictions)} –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
        return predictions
    
    def _create_basic_predictions(self) -> List[Tuple[Tuple[int, int, int, int], float]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö —Å –º–æ–¥–µ–ª—å—é"""
        import random
        predictions = []
        for i in range(4):
            # –°–æ–∑–¥–∞–µ–º –≥—Ä—É–ø–ø—É —Å —Ä–∞–∑–Ω—ã–º–∏ —á–∏—Å–ª–∞–º–∏
            while True:
                group = tuple(random.sample(range(1, 27), 4))
                if len(set(group)) == 4:  # –í—Å–µ —á–∏—Å–ª–∞ —Ä–∞–∑–Ω—ã–µ
                    predictions.append((group, 0.001))
                    break
        return predictions
        
    def _save_model(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        self._report_progress("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∏—Å–∫...")
        
        if self.model is not None:
            os.makedirs(os.path.dirname(self.model_path), exist_ok=True)
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'model_config': {
                    'input_size': self.model.input_size,
                    'hidden_size': self.model.hidden_size
                }
            }, self.model_path)
            
            self._report_progress(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {self.model_path}")
